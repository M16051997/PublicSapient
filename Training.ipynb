{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad113333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files removed: 78 (61.5 MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip cache purge\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8385a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SIMPLE LOAN DEFAULT PREDICTION - 3 MODELS APPROACH\n",
    "No SMOTE, No Complex Techniques - Just Good Models + Class Weights\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score, \n",
    "    roc_curve, precision_recall_curve, auc, f1_score\n",
    ")\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84652ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOAN DEFAULT PREDICTION - SIMPLE & EFFECTIVE APPROACH\n",
      "================================================================================\n",
      "\n",
      "üìä Step 1: Loading processed data...\n",
      "\n",
      "‚úì Data loaded successfully!\n",
      "  - Features (X): (121856, 54)\n",
      "  - Target (y): (121856,)\n",
      "\n",
      "‚úì Target distribution:\n",
      "  - Non-Default (0): 112,011 (91.9%)\n",
      "  - Default (1): 9,845 (8.1%)\n",
      "  - Imbalance Ratio: 11.4:1\n",
      "\n",
      "================================================================================\n",
      "üìä Step 2: Train/Test Split (Stratified)\n",
      "================================================================================\n",
      "\n",
      "‚úì Split complete!\n",
      "  - Train: 97,484 samples (80%)\n",
      "  - Test:  24,372 samples (20%)\n",
      "\n",
      "‚úì Class distribution maintained:\n",
      "  Train - Default: 7,876 (8.1%)\n",
      "  Test  - Default: 1,969 (8.1%)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"LOAN DEFAULT PREDICTION - SIMPLE & EFFECTIVE APPROACH\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: LOAD PROCESSED DATA\n",
    "# ============================================================================\n",
    "print(\"\\nüìä Step 1: Loading processed data...\")\n",
    "\n",
    "X = pd.read_csv('processed_data/X_selected.csv') # \\X_selected.csv\n",
    "y = pd.read_csv('processed_data/y_target.csv').values.ravel()\n",
    "\n",
    "print(f\"\\n‚úì Data loaded successfully!\")\n",
    "print(f\"  - Features (X): {X.shape}\")\n",
    "print(f\"  - Target (y): {y.shape}\")\n",
    "print(f\"\\n‚úì Target distribution:\")\n",
    "print(f\"  - Non-Default (0): {(y == 0).sum():,} ({(y == 0).sum()/len(y)*100:.1f}%)\")\n",
    "print(f\"  - Default (1): {(y == 1).sum():,} ({(y == 1).sum()/len(y)*100:.1f}%)\")\n",
    "print(f\"  - Imbalance Ratio: {(y == 0).sum()/(y == 1).sum():.1f}:1\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: TRAIN/TEST SPLIT (Stratified)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä Step 2: Train/Test Split (Stratified)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 80/20 split, stratified to maintain 11.4:1 ratio\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y  # CRITICAL: Maintains class distribution\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Split complete!\")\n",
    "print(f\"  - Train: {X_train.shape[0]:,} samples ({X_train.shape[0]/len(X)*100:.0f}%)\")\n",
    "print(f\"  - Test:  {X_test.shape[0]:,} samples ({X_test.shape[0]/len(X)*100:.0f}%)\")\n",
    "\n",
    "print(f\"\\n‚úì Class distribution maintained:\")\n",
    "print(f\"  Train - Default: {(y_train == 1).sum():,} ({(y_train == 1).sum()/len(y_train)*100:.1f}%)\")\n",
    "print(f\"  Test  - Default: {(y_test == 1).sum():,} ({(y_test == 1).sum()/len(y_test)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f1541b",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bb4db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 1: Loading processed data for encoding...\n",
      "================================================================================\n",
      "Data loaded: (121856, 54), Target: (121856,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder, TargetEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# =====================================================================\n",
    "# STEP 1: LOAD DATA\n",
    "# =====================================================================\n",
    "print(\"=\" * 80)\n",
    "print(\"STEP 1: Loading processed data for encoding...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "X = pd.read_csv('processed_data/X_selected.csv')\n",
    "y = pd.read_csv('processed_data/y_target.csv').values.ravel()\n",
    "\n",
    "print(f\"Data loaded: {X.shape}, Target: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff248b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Client_Income', 'Car_Owned', 'Bike_Owned', 'Active_Loan', 'House_Own',\n",
       "       'Child_Count', 'Credit_Amount', 'Loan_Annuity', 'Accompany_Client',\n",
       "       'Client_Income_Type', 'Client_Education', 'Client_Marital_Status',\n",
       "       'Client_Gender', 'Loan_Contract_Type', 'Client_Housing_Type',\n",
       "       'Population_Region_Relative', 'Registration_Days', 'ID_Days',\n",
       "       'Own_House_Age', 'Mobile_Tag', 'Homephone_Tag', 'Workphone_Working',\n",
       "       'Client_Occupation', 'Client_Family_Members', 'Cleint_City_Rating',\n",
       "       'Application_Process_Day', 'Application_Process_Hour',\n",
       "       'Client_Permanent_Match_Tag', 'Client_Contact_Work_Tag',\n",
       "       'Type_Organization', 'Score_Source_1', 'Score_Source_2',\n",
       "       'Score_Source_3', 'Social_Circle_Default', 'Phone_Change',\n",
       "       'Credit_Bureau', 'Has_House_Age_Info', 'Score_Source_1_Available',\n",
       "       'Score_Source_2_Available', 'Score_Source_3_Available',\n",
       "       'Num_Credit_Scores_Available', 'Has_Credit_Bureau_Record',\n",
       "       'Social_Circle_Data_Available', 'Has_Employment_History',\n",
       "       'Occupation_Disclosed', 'Credit_Income_Ratio', 'Annuity_Income_Ratio',\n",
       "       'Monthly_Payment_Burden', 'Credit_Annuity_Ratio', 'Is_Unemployed',\n",
       "       'Employment_Years', 'Age_Years', 'Total_Assets_Owned',\n",
       "       'Min_External_Score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d554a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Client_Income</th>\n",
       "      <th>Car_Owned</th>\n",
       "      <th>Bike_Owned</th>\n",
       "      <th>Active_Loan</th>\n",
       "      <th>House_Own</th>\n",
       "      <th>Child_Count</th>\n",
       "      <th>Credit_Amount</th>\n",
       "      <th>Loan_Annuity</th>\n",
       "      <th>Accompany_Client</th>\n",
       "      <th>Client_Income_Type</th>\n",
       "      <th>Client_Education</th>\n",
       "      <th>Client_Marital_Status</th>\n",
       "      <th>Client_Gender</th>\n",
       "      <th>Loan_Contract_Type</th>\n",
       "      <th>Client_Housing_Type</th>\n",
       "      <th>Population_Region_Relative</th>\n",
       "      <th>Registration_Days</th>\n",
       "      <th>ID_Days</th>\n",
       "      <th>Own_House_Age</th>\n",
       "      <th>Mobile_Tag</th>\n",
       "      <th>Homephone_Tag</th>\n",
       "      <th>Workphone_Working</th>\n",
       "      <th>Client_Occupation</th>\n",
       "      <th>Client_Family_Members</th>\n",
       "      <th>Cleint_City_Rating</th>\n",
       "      <th>Application_Process_Day</th>\n",
       "      <th>Application_Process_Hour</th>\n",
       "      <th>Client_Permanent_Match_Tag</th>\n",
       "      <th>Client_Contact_Work_Tag</th>\n",
       "      <th>Type_Organization</th>\n",
       "      <th>Score_Source_1</th>\n",
       "      <th>Score_Source_2</th>\n",
       "      <th>Score_Source_3</th>\n",
       "      <th>Social_Circle_Default</th>\n",
       "      <th>Phone_Change</th>\n",
       "      <th>Credit_Bureau</th>\n",
       "      <th>Has_House_Age_Info</th>\n",
       "      <th>Score_Source_1_Available</th>\n",
       "      <th>Score_Source_2_Available</th>\n",
       "      <th>Score_Source_3_Available</th>\n",
       "      <th>Num_Credit_Scores_Available</th>\n",
       "      <th>Has_Credit_Bureau_Record</th>\n",
       "      <th>Social_Circle_Data_Available</th>\n",
       "      <th>Has_Employment_History</th>\n",
       "      <th>Occupation_Disclosed</th>\n",
       "      <th>Credit_Income_Ratio</th>\n",
       "      <th>Annuity_Income_Ratio</th>\n",
       "      <th>Monthly_Payment_Burden</th>\n",
       "      <th>Credit_Annuity_Ratio</th>\n",
       "      <th>Is_Unemployed</th>\n",
       "      <th>Employment_Years</th>\n",
       "      <th>Age_Years</th>\n",
       "      <th>Total_Assets_Owned</th>\n",
       "      <th>Min_External_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6750.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61190.55</td>\n",
       "      <td>3416.85</td>\n",
       "      <td>Alone</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Secondary</td>\n",
       "      <td>M</td>\n",
       "      <td>Male</td>\n",
       "      <td>CL</td>\n",
       "      <td>Home</td>\n",
       "      <td>0.028663</td>\n",
       "      <td>-6123.0</td>\n",
       "      <td>-383.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Sales</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>0.568066</td>\n",
       "      <td>0.478787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0186</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.063924</td>\n",
       "      <td>0.506125</td>\n",
       "      <td>6.073500</td>\n",
       "      <td>17.903229</td>\n",
       "      <td>0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>38.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20250.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15282.00</td>\n",
       "      <td>1826.55</td>\n",
       "      <td>Alone</td>\n",
       "      <td>Service</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>M</td>\n",
       "      <td>Male</td>\n",
       "      <td>CL</td>\n",
       "      <td>Home</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>-7833.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Not_Disclosed</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Government</td>\n",
       "      <td>0.563360</td>\n",
       "      <td>0.215068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>755.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.754629</td>\n",
       "      <td>0.090196</td>\n",
       "      <td>1.082347</td>\n",
       "      <td>8.362015</td>\n",
       "      <td>0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>38.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59527.35</td>\n",
       "      <td>2788.20</td>\n",
       "      <td>Alone</td>\n",
       "      <td>Service</td>\n",
       "      <td>Graduation dropout</td>\n",
       "      <td>W</td>\n",
       "      <td>Male</td>\n",
       "      <td>CL</td>\n",
       "      <td>Family</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>-4493.0</td>\n",
       "      <td>-331.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Realty agents</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.552795</td>\n",
       "      <td>0.329655</td>\n",
       "      <td>0.0742</td>\n",
       "      <td>277.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.306891</td>\n",
       "      <td>0.154891</td>\n",
       "      <td>1.858697</td>\n",
       "      <td>21.342087</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15750.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53870.40</td>\n",
       "      <td>2295.45</td>\n",
       "      <td>Alone</td>\n",
       "      <td>Retired</td>\n",
       "      <td>Secondary</td>\n",
       "      <td>M</td>\n",
       "      <td>Male</td>\n",
       "      <td>CL</td>\n",
       "      <td>Home</td>\n",
       "      <td>0.010556</td>\n",
       "      <td>-4493.0</td>\n",
       "      <td>-775.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Not_Disclosed</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Not_Disclosed</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135182</td>\n",
       "      <td>0.631355</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.420126</td>\n",
       "      <td>0.145734</td>\n",
       "      <td>1.748803</td>\n",
       "      <td>23.458120</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>63.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33750.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>133988.40</td>\n",
       "      <td>3547.35</td>\n",
       "      <td>Alone</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>Secondary</td>\n",
       "      <td>M</td>\n",
       "      <td>Female</td>\n",
       "      <td>CL</td>\n",
       "      <td>Home</td>\n",
       "      <td>0.020713</td>\n",
       "      <td>-5516.0</td>\n",
       "      <td>-4043.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Business Entity Type 3</td>\n",
       "      <td>0.508199</td>\n",
       "      <td>0.301182</td>\n",
       "      <td>0.355639</td>\n",
       "      <td>0.2021</td>\n",
       "      <td>674.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.969909</td>\n",
       "      <td>0.105104</td>\n",
       "      <td>1.261243</td>\n",
       "      <td>37.760762</td>\n",
       "      <td>0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>31.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.301182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Client_Income  Car_Owned  ...  Total_Assets_Owned  Min_External_Score\n",
       "0         6750.0          0  ...                   0            0.000000\n",
       "1        20250.0          1  ...                   1            0.000000\n",
       "2        18000.0          0  ...                   0            0.000000\n",
       "3        15750.0          0  ...                   1            0.000000\n",
       "4        33750.0          1  ...                   1            0.301182\n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252d426d",
   "metadata": {},
   "source": [
    "<!-- \n",
    "Never use LabelEncoder for features - it will hurt your model\n",
    "Target encoding captures the relationship between categories and default probability\n",
    "One-hot encoding preserves the independence of nominal categories\n",
    "Always validate your encoding choices with cross-validation \n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b14a4ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accompany_Client\n",
       "Alone       99167\n",
       "Relative    15748\n",
       "Partner      4516\n",
       "Kids         1334\n",
       "Others        987\n",
       "Group         104\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Accompany_Client'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83923b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Client_Housing_Type\n",
       "Home         108557\n",
       "Family         5783\n",
       "Municipal      4248\n",
       "Rental         1816\n",
       "Office         1002\n",
       "Shared          450\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Client_Housing_Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868fe3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Feature Distribution:\n",
      "  - One-Hot Encoding: 5 features\n",
      "  - Target Encoding: 3 features\n",
      "  - Ordinal Encoding: 2 features\n",
      "  - Numerical: 44 features\n",
      "  - Total: 54 features\n",
      "\\nüîÑ Fitting encoders on training data...\n",
      "  Train shape: (97484, 54)\n",
      "  Test shape: (24372, 54)\n",
      "\\n‚úÖ Encoding complete!\n",
      "  Encoded train shape: (97484, 67)\n",
      "  Encoded test shape: (24372, 67)\n",
      "\\nüíæ Saving artifacts...\n",
      "\\n‚úÖ All files saved successfully!\n",
      "  - artifacts/preprocessor_with_target_encoder.pkl\n",
      "  - processed_data/X_train_encoded.csv\n",
      "  - processed_data/X_test_encoded.csv\n",
      "  - artifacts/encoded_feature_names.csv\n",
      "\\nüìà Encoding Summary:\n",
      "  Original features: 54\n",
      "  Encoded features: 67\n",
      "  Feature expansion: 13\n",
      "\n",
      "======================================================================\n",
      "ENCODING STRATEGY SUMMARY\n",
      "======================================================================\n",
      "\n",
      "1. One-Hot Encoding (for low cardinality nominal):\n",
      "   - Client_Gender\n",
      "   - Loan_Contract_Type\n",
      "   - Client_Marital_Status\n",
      "   - Accompany_Client\n",
      "   - Client_Housing_Type\n",
      "\n",
      "2. Target Encoding (for high cardinality nominal):\n",
      "   - Client_Occupation\n",
      "   - Type_Organization\n",
      "   - Client_Income_Type\n",
      "   ‚Üí Reduces dimensionality while capturing relationship with default rate\n",
      "\n",
      "3. Ordinal Encoding (for features with natural order):\n",
      "   - Client_Education\n",
      "   - Cleint_City_Rating\n",
      "\n",
      "4. Standard Scaling applied to all numerical features\n",
      "\n",
      "======================================================================\n",
      "KEY BENEFITS OF THIS APPROACH:\n",
      "======================================================================\n",
      "‚úì Preserves information from high cardinality features\n",
      "‚úì Avoids creating arbitrary ordinal relationships\n",
      "‚úì Reduces dimensionality compared to one-hot encoding everything\n",
      "‚úì Built-in cross-validation in TargetEncoder prevents overfitting\n",
      "‚úì Handles unknown categories gracefully\n",
      "‚úì All sklearn native - no external dependencies\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Quick Implementation Script for Loan Default Encoding\n",
    "====================================================\n",
    "This script shows how to use the LoanDefaultEncoder with your actual data.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder, \n",
    "    OrdinalEncoder, \n",
    "    TargetEncoder,\n",
    "    StandardScaler\n",
    ")\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs('artifacts', exist_ok=True)\n",
    "os.makedirs('processed_data', exist_ok=True)\n",
    "\n",
    "# =====================================================================\n",
    "# DEFINE YOUR FEATURES\n",
    "# =====================================================================\n",
    "features_to_use = [\n",
    "    'Client_Income', 'Car_Owned', 'Bike_Owned', 'Active_Loan', 'House_Own',\n",
    "    'Child_Count', 'Credit_Amount', 'Loan_Annuity', 'Accompany_Client',\n",
    "    'Client_Income_Type', 'Client_Education', 'Client_Marital_Status',\n",
    "    'Client_Gender', 'Loan_Contract_Type', 'Client_Housing_Type',\n",
    "    'Population_Region_Relative', 'Registration_Days', 'ID_Days',\n",
    "    'Own_House_Age', 'Mobile_Tag', 'Homephone_Tag', 'Workphone_Working',\n",
    "    'Client_Occupation', 'Client_Family_Members', 'Cleint_City_Rating',\n",
    "    'Application_Process_Day', 'Application_Process_Hour',\n",
    "    'Client_Permanent_Match_Tag', 'Client_Contact_Work_Tag',\n",
    "    'Type_Organization', 'Score_Source_1', 'Score_Source_2',\n",
    "    'Score_Source_3', 'Social_Circle_Default', 'Phone_Change',\n",
    "    'Credit_Bureau', 'Has_House_Age_Info', 'Score_Source_1_Available',\n",
    "    'Score_Source_2_Available', 'Score_Source_3_Available',\n",
    "    'Num_Credit_Scores_Available', 'Has_Credit_Bureau_Record',\n",
    "    'Social_Circle_Data_Available', 'Has_Employment_History',\n",
    "    'Occupation_Disclosed', 'Credit_Income_Ratio', 'Annuity_Income_Ratio',\n",
    "    'Monthly_Payment_Burden', 'Credit_Annuity_Ratio', 'Is_Unemployed',\n",
    "    'Employment_Years', 'Age_Years', 'Total_Assets_Owned',\n",
    "    'Min_External_Score'\n",
    "]\n",
    "\n",
    "# =====================================================================\n",
    "# CATEGORIZE FEATURES BY TYPE\n",
    "# =====================================================================\n",
    "\n",
    "# Low cardinality nominal features ‚Üí One-Hot Encoding\n",
    "onehot_features = [\n",
    "    'Client_Gender',           # Binary: M/F\n",
    "    'Loan_Contract_Type',      # Binary: CL/RL\n",
    "    'Client_Marital_Status',   # Low cardinality: D/S/M/W\n",
    "    'Accompany_Client',        # Low cardinality\n",
    "    'Client_Housing_Type',     # Low cardinality\n",
    "]\n",
    "\n",
    "# High cardinality nominal features ‚Üí Target Encoding\n",
    "target_encoded_features = [\n",
    "    'Client_Occupation',       # Many different occupations\n",
    "    'Type_Organization',       # Many organization types\n",
    "    'Client_Income_Type',      # Several income types\n",
    "]\n",
    "\n",
    "# Ordinal features ‚Üí Ordinal Encoding\n",
    "ordinal_features = [\n",
    "    'Client_Education',        # Has natural ordering\n",
    "    'Cleint_City_Rating',      # Already numeric 1-2-3\n",
    "]\n",
    "\n",
    "# All remaining features are numerical\n",
    "numerical_features = [\n",
    "    feat for feat in features_to_use \n",
    "    if feat not in onehot_features + target_encoded_features + ordinal_features\n",
    "]\n",
    "\n",
    "print(f\"üìä Feature Distribution:\")\n",
    "print(f\"  - One-Hot Encoding: {len(onehot_features)} features\")\n",
    "print(f\"  - Target Encoding: {len(target_encoded_features)} features\")\n",
    "print(f\"  - Ordinal Encoding: {len(ordinal_features)} features\")\n",
    "print(f\"  - Numerical: {len(numerical_features)} features\")\n",
    "print(f\"  - Total: {len(features_to_use)} features\")\n",
    "\n",
    "# =====================================================================\n",
    "# CREATE PREPROCESSING PIPELINES\n",
    "# =====================================================================\n",
    "\n",
    "# Pipeline for one-hot encoded features\n",
    "onehot_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('encoder', OneHotEncoder(\n",
    "        handle_unknown='ignore',\n",
    "        sparse_output=False,\n",
    "        drop='if_binary'  # Drops one category for binary features to avoid multicollinearity\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Pipeline for target encoded features\n",
    "target_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('encoder', TargetEncoder(\n",
    "        smooth='auto',        # Automatic smoothing based on category frequency\n",
    "        target_type='binary', # We have binary classification\n",
    "        cv=5,                # Use 5-fold CV to prevent overfitting\n",
    "        shuffle=True,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Pipeline for ordinal features\n",
    "# Define education order (you may need to adjust based on your actual categories)\n",
    "education_categories = [\n",
    "    ['Secondary', 'Higher education', 'Incomplete higher', \n",
    "     'Lower secondary', 'Academic degree']  # Adjust based on your data\n",
    "]\n",
    "\n",
    "ordinal_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OrdinalEncoder(\n",
    "        handle_unknown='use_encoded_value',\n",
    "        unknown_value=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Pipeline for numerical features Normalization/Standaridzation\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')), # StandardScaler cannot handle NaN values - it will throw an error if it encounters any missing data.\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# =====================================================================\n",
    "# COMBINE ALL PIPELINES\n",
    "# =====================================================================\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', onehot_pipeline, onehot_features),\n",
    "        ('target', target_pipeline, target_encoded_features),\n",
    "        ('ordinal', ordinal_pipeline, ordinal_features),\n",
    "        ('numerical', numerical_pipeline, numerical_features)\n",
    "    ],\n",
    "    remainder='drop',     # Drop any columns not specified\n",
    "    n_jobs=-1,           # Use all CPU cores\n",
    "    verbose=True         # Show progress\n",
    ")\n",
    "\n",
    "# =====================================================================\n",
    "# USAGE EXAMPLE (uncomment and modify for your data)\n",
    "# =====================================================================\n",
    "\n",
    "# Load your data\n",
    "X = pd.read_csv('processed_data/X_selected.csv')\n",
    "y = pd.read_csv('processed_data/y_target.csv') #.values.ravel()\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\\\nüîÑ Fitting encoders on training data...\")\n",
    "print(f\"  Train shape: {X_train.shape}\")\n",
    "print(f\"  Test shape: {X_test.shape}\")\n",
    "\n",
    "# Fit on training data\n",
    "X_train_encoded = preprocessor.fit_transform(X_train, y_train)\n",
    "\n",
    "# Transform test data\n",
    "X_test_encoded = preprocessor.transform(X_test)\n",
    "\n",
    "# Get feature names after transformation\n",
    "def get_feature_names_out(preprocessor, input_features):\n",
    "    '''Get feature names after preprocessing'''\n",
    "    output_features = []\n",
    "    \n",
    "    # Get names from each transformer\n",
    "    for name, transformer, features in preprocessor.transformers_:\n",
    "        if name == 'onehot':\n",
    "            # Get one-hot encoded names\n",
    "            feature_names = transformer.named_steps['encoder'].get_feature_names_out(features)\n",
    "            output_features.extend(feature_names)\n",
    "        elif name in ['target', 'ordinal']:\n",
    "            # Target and ordinal encoded features keep original names\n",
    "            output_features.extend(features)\n",
    "        elif name == 'numerical':\n",
    "            # Numerical features keep original names\n",
    "            output_features.extend(features)\n",
    "    \n",
    "    return output_features\n",
    "\n",
    "# Get feature names\n",
    "feature_names_out = get_feature_names_out(preprocessor, features_to_use)\n",
    "\n",
    "# Convert to DataFrames with proper column names\n",
    "X_train_encoded_df = pd.DataFrame(X_train_encoded, columns=feature_names_out)\n",
    "X_test_encoded_df = pd.DataFrame(X_test_encoded, columns=feature_names_out)\n",
    "\n",
    "print(f\"\\\\n‚úÖ Encoding complete!\")\n",
    "print(f\"  Encoded train shape: {X_train_encoded_df.shape}\")\n",
    "print(f\"  Encoded test shape: {X_test_encoded_df.shape}\")\n",
    "\n",
    "# Save everything\n",
    "print(f\"\\\\nüíæ Saving artifacts...\")\n",
    "\n",
    "# Save the preprocessor\n",
    "joblib.dump(preprocessor, 'artifacts/preprocessor_with_target_encoder.pkl')\n",
    "\n",
    "# Save encoded data\n",
    "X_train_encoded_df.to_csv('processed_data/X_train_encoded.csv', index=False)\n",
    "X_test_encoded_df.to_csv('processed_data/X_test_encoded.csv', index=False)\n",
    "y_train.to_csv('processed_data/y_train.csv', index=False)\n",
    "y_test.to_csv('processed_data/y_test.csv', index=False)\n",
    "\n",
    "# Save feature names for reference\n",
    "pd.DataFrame({\n",
    "    'feature_name': feature_names_out,\n",
    "    'feature_type': ['encoded'] * len(feature_names_out)\n",
    "}).to_csv('artifacts/encoded_feature_names.csv', index=False)\n",
    "\n",
    "print(f\"\\\\n‚úÖ All files saved successfully!\")\n",
    "print(f\"  - artifacts/preprocessor_with_target_encoder.pkl\")\n",
    "print(f\"  - processed_data/X_train_encoded.csv\")\n",
    "print(f\"  - processed_data/X_test_encoded.csv\")\n",
    "print(f\"  - artifacts/encoded_feature_names.csv\")\n",
    "\n",
    "# Print encoding summary\n",
    "print(f\"\\\\nüìà Encoding Summary:\")\n",
    "print(f\"  Original features: {X_train.shape[1]}\")\n",
    "print(f\"  Encoded features: {X_train_encoded_df.shape[1]}\")\n",
    "print(f\"  Feature expansion: {X_train_encoded_df.shape[1] - X_train.shape[1]}\")\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# QUICK REFERENCE\n",
    "# =====================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ENCODING STRATEGY SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n1. One-Hot Encoding (for low cardinality nominal):\")\n",
    "for feat in onehot_features:\n",
    "    print(f\"   - {feat}\")\n",
    "\n",
    "print(\"\\n2. Target Encoding (for high cardinality nominal):\")\n",
    "for feat in target_encoded_features:\n",
    "    print(f\"   - {feat}\")\n",
    "print(\"   ‚Üí Reduces dimensionality while capturing relationship with default rate\")\n",
    "\n",
    "print(\"\\n3. Ordinal Encoding (for features with natural order):\")\n",
    "for feat in ordinal_features:\n",
    "    print(f\"   - {feat}\")\n",
    "\n",
    "print(\"\\n4. Standard Scaling applied to all numerical features\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY BENEFITS OF THIS APPROACH:\")\n",
    "print(\"=\"*70)\n",
    "print(\"‚úì Preserves information from high cardinality features\")\n",
    "print(\"‚úì Avoids creating arbitrary ordinal relationships\")\n",
    "print(\"‚úì Reduces dimensionality compared to one-hot encoding everything\")\n",
    "print(\"‚úì Built-in cross-validation in TargetEncoder prevents overfitting\")\n",
    "print(\"‚úì Handles unknown categories gracefully\")\n",
    "print(\"‚úì All sklearn native - no external dependencies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffacfb36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type_Organization\n",
       "Business Entity Type 3    26279\n",
       "Not_Disclosed             24688\n",
       "Self-employed             14725\n",
       "Other                      6290\n",
       "Medicine                   4320\n",
       "Business Entity Type 2     4126\n",
       "Government                 3971\n",
       "School                     3371\n",
       "Trade: type 7              2979\n",
       "Kindergarten               2686\n",
       "Construction               2623\n",
       "Business Entity Type 1     2313\n",
       "Transport: type 4          2076\n",
       "Trade: type 3              1338\n",
       "Security                   1284\n",
       "Industry: type 9           1280\n",
       "Industry: type 3           1235\n",
       "Housing                    1162\n",
       "Military                   1031\n",
       "Bank                       1012\n",
       "Agriculture                1011\n",
       "Industry: type 11           999\n",
       "Police                      934\n",
       "Postal                      834\n",
       "Transport: type 2           811\n",
       "Security Ministries         756\n",
       "Trade: type 2               717\n",
       "Restaurant                  710\n",
       "Services                    570\n",
       "University                  559\n",
       "Transport: type 3           501\n",
       "Industry: type 7            497\n",
       "Industry: type 1            401\n",
       "Hotel                       393\n",
       "Electricity                 366\n",
       "Industry: type 4            337\n",
       "Trade: type 6               249\n",
       "Industry: type 5            232\n",
       "Telecom                     225\n",
       "Insurance                   215\n",
       "Emergency                   207\n",
       "Industry: type 2            172\n",
       "Realtor                     156\n",
       "Industry: type 12           153\n",
       "Advertising                 152\n",
       "Trade: type 1               135\n",
       "Culture                     131\n",
       "Mobile                      122\n",
       "Legal Services              119\n",
       "Cleaning                    118\n",
       "Transport: type 1            77\n",
       "Industry: type 6             40\n",
       "Industry: type 10            40\n",
       "Religion                     37\n",
       "Industry: type 13            35\n",
       "Trade: type 4                28\n",
       "Trade: type 5                12\n",
       "Industry: type 8             10\n",
       "Not_Applicable                6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X['Accompany_Client'].value_counts() #  6 categories Label Encoding\n",
    "# X['Client_Income_Type'].value_counts() #  8 categories Label Encoding\n",
    "# X['Client_Education'].value_counts() # 4 categories Label Encoding\n",
    "# X['Client_Marital_Status'].value_counts() # 4 categories Label Encoding\n",
    "# X['Client_Gender'].value_counts() # 2 categories onehot Encoding\n",
    "# X['Loan_Contract_Type'].value_counts() # 2 categories onehot Encoding\n",
    "# X['Client_Housing_Type'].value_counts() # 6 categories Label Encoding\n",
    "# X['Client_Occupation'].value_counts() # more than 16 categories Label Encoding\n",
    "# X['Type_Organization'].value_counts() # more than 26 categories Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd542c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "üè¶ LOAN DEFAULT PREDICTION - BOOSTING MODEL TRAINING PIPELINE\n",
      "====================================================================================================\n",
      "\n",
      "üì• Loading encoded data...\n",
      "‚úì Training data shape: (97484, 67)\n",
      "‚úì Testing  data shape: (24372, 67)\n",
      "‚úì Target imbalance ratio: 11.4:1\n",
      "\n",
      "‚öñÔ∏è Calculated scale_pos_weight: 11.38\n",
      "\n",
      "====================================================================================================\n",
      "üöÄ Training Model: Logistic Regression\n",
      "====================================================================================================\n",
      "\n",
      "‚úÖ Model trained in 2.80s\n",
      "üéØ AUC-ROC: 0.7331 | AUC-PR: 0.2017\n",
      "üìä Recall (Default): 67.34%\n",
      "üìä Precision (Default): 15.52%\n",
      "üìä F1-Score (Default): 0.2523\n",
      "\n",
      "üìã Confusion Matrix:\n",
      "                 Predicted\n",
      "               No Default  Default\n",
      "  Actual No    15,185     7,218\n",
      "         Yes      643     1,326\n",
      "\n",
      "‚ö†Ô∏è Missed Defaults: 643 √ó $315,000 = $202,545,000\n",
      "\n",
      "====================================================================================================\n",
      "üöÄ Training Model: XGBoost\n",
      "====================================================================================================\n",
      "\n",
      "‚úÖ Model trained in 4.49s\n",
      "üéØ AUC-ROC: 0.7665 | AUC-PR: 0.2483\n",
      "üìä Recall (Default): 71.97%\n",
      "üìä Precision (Default): 16.68%\n",
      "üìä F1-Score (Default): 0.2708\n",
      "\n",
      "üìã Confusion Matrix:\n",
      "                 Predicted\n",
      "               No Default  Default\n",
      "  Actual No    15,323     7,080\n",
      "         Yes      552     1,417\n",
      "\n",
      "‚ö†Ô∏è Missed Defaults: 552 √ó $315,000 = $173,880,000\n",
      "\n",
      "====================================================================================================\n",
      "üöÄ Training Model: LightGBM\n",
      "====================================================================================================\n",
      "\n",
      "‚úÖ Model trained in 4.13s\n",
      "üéØ AUC-ROC: 0.7637 | AUC-PR: 0.2377\n",
      "üìä Recall (Default): 62.21%\n",
      "üìä Precision (Default): 19.30%\n",
      "üìä F1-Score (Default): 0.2946\n",
      "\n",
      "üìã Confusion Matrix:\n",
      "                 Predicted\n",
      "               No Default  Default\n",
      "  Actual No    17,282     5,121\n",
      "         Yes      744     1,225\n",
      "\n",
      "‚ö†Ô∏è Missed Defaults: 744 √ó $315,000 = $234,360,000\n",
      "üíæ Saved Logistic Regression model ‚Üí artifacts/models/logistic_regression.pkl\n",
      "üíæ Saved XGBoost model ‚Üí artifacts/models/xgboost.pkl\n",
      "üíæ Saved LightGBM model ‚Üí artifacts/models/lightgbm.pkl\n",
      "\n",
      "üìä Summary of Model Performance:\n",
      "                 Model   AUC-ROC  ...  F1-Score (Default)  Train Time (s)\n",
      "0  Logistic Regression  0.733106  ...            0.252259            2.80\n",
      "1              XGBoost  0.766528  ...            0.270782            4.49\n",
      "2             LightGBM  0.763676  ...            0.294648            4.13\n",
      "\n",
      "[3 rows x 7 columns]\n",
      "\n",
      "‚úÖ Pipeline completed successfully! All models saved for deployment.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, precision_recall_curve, auc,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"üè¶ LOAN DEFAULT PREDICTION - BOOSTING MODEL TRAINING PIPELINE\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# =====================================================================\n",
    "# STEP 1: LOAD ENCODED DATA\n",
    "# =====================================================================\n",
    "print(\"\\nüì• Loading encoded data...\")\n",
    "\n",
    "X_train = pd.read_csv('processed_data/X_train_encoded.csv')\n",
    "X_test = pd.read_csv('processed_data/X_test_encoded.csv')\n",
    "y_train = pd.read_csv('processed_data/y_train.csv').values.ravel()\n",
    "y_test = pd.read_csv('processed_data/y_test.csv').values.ravel()\n",
    "\n",
    "print(f\"‚úì Training data shape: {X_train.shape}\")\n",
    "print(f\"‚úì Testing  data shape: {X_test.shape}\")\n",
    "print(f\"‚úì Target imbalance ratio: {(y_train==0).sum() / (y_train==1).sum():.1f}:1\")\n",
    "\n",
    "# =====================================================================\n",
    "# STEP 2: MODEL CONFIGURATION\n",
    "# =====================================================================\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"\\n‚öñÔ∏è Calculated scale_pos_weight: {scale_pos_weight:.2f}\")\n",
    "\n",
    "scale_pos_weight = 20\n",
    "\n",
    "models_config = {\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        class_weight='balanced', max_iter=1000, random_state=42\n",
    "    ),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        n_estimators=500,\n",
    "        min_child_weight=1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        eval_metric='auc',\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \"LightGBM\": LGBMClassifier(\n",
    "        is_unbalance=True,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        n_estimators=500,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "}\n",
    "\n",
    "# =====================================================================\n",
    "# STEP 3: TRAINING LOOP\n",
    "# =====================================================================\n",
    "def train_and_evaluate(models, X_train, y_train, X_test, y_test):\n",
    "    results = []\n",
    "    trained_models = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(\"\\n\" + \"=\"*100)\n",
    "        print(f\"üöÄ Training Model: {name}\")\n",
    "        print(\"=\"*100)\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Fit model\n",
    "        model.fit(X_train, y_train)\n",
    "        duration = time.time() - start_time\n",
    "        \n",
    "        # Predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Metrics\n",
    "        auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "        precision_vals, recall_vals, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "        auc_pr = auc(recall_vals, precision_vals)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        # Log results\n",
    "        results.append({\n",
    "            \"Model\": name,\n",
    "            \"AUC-ROC\": auc_roc,\n",
    "            \"AUC-PR\": auc_pr,\n",
    "            \"Recall (Default)\": report['1']['recall'],\n",
    "            \"Precision (Default)\": report['1']['precision'],\n",
    "            \"F1-Score (Default)\": report['1']['f1-score'],\n",
    "            \"Train Time (s)\": round(duration, 2)\n",
    "        })\n",
    "        \n",
    "        print(f\"\\n‚úÖ Model trained in {duration:.2f}s\")\n",
    "        print(f\"üéØ AUC-ROC: {auc_roc:.4f} | AUC-PR: {auc_pr:.4f}\")\n",
    "        print(f\"üìä Recall (Default): {report['1']['recall']:.2%}\")\n",
    "        print(f\"üìä Precision (Default): {report['1']['precision']:.2%}\")\n",
    "        print(f\"üìä F1-Score (Default): {report['1']['f1-score']:.4f}\")\n",
    "        print(f\"\\nüìã Confusion Matrix:\")\n",
    "        print(f\"                 Predicted\")\n",
    "        print(f\"               No Default  Default\")\n",
    "        print(f\"  Actual No    {cm[0,0]:>6,}    {cm[0,1]:>6,}\")\n",
    "        print(f\"         Yes   {cm[1,0]:>6,}    {cm[1,1]:>6,}\")\n",
    "        print(f\"\\n‚ö†Ô∏è Missed Defaults: {cm[1,0]:,} √ó $315,000 = ${cm[1,0]*315000:,.0f}\")\n",
    "\n",
    "        # Store trained model\n",
    "        trained_models[name] = model\n",
    "\n",
    "    return pd.DataFrame(results), trained_models\n",
    "\n",
    "\n",
    "results_df, trained_models = train_and_evaluate(models_config, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# =====================================================================\n",
    "# STEP 4: SAVE MODELS AND RESULTS\n",
    "# =====================================================================\n",
    "os.makedirs(\"artifacts/models\", exist_ok=True)\n",
    "os.makedirs(\"artifacts/reports\", exist_ok=True)\n",
    "\n",
    "for name, model in trained_models.items():\n",
    "    path = f\"artifacts/models/{name.replace(' ', '_').lower()}.pkl\"\n",
    "    joblib.dump(model, path)\n",
    "    print(f\"üíæ Saved {name} model ‚Üí {path}\")\n",
    "\n",
    "results_df.to_csv(\"artifacts/reports/model_results.csv\", index=False)\n",
    "print(\"\\nüìä Summary of Model Performance:\")\n",
    "print(results_df)\n",
    "\n",
    "print(\"\\n‚úÖ Pipeline completed successfully! All models saved for deployment.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bc5f0e",
   "metadata": {},
   "source": [
    "#### Updated pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2512cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "üè¶ ENHANCED LOAN DEFAULT PREDICTION - MODEL TRAINING PIPELINE\n",
      "====================================================================================================\n",
      "\n",
      "üì• Loading encoded data...\n",
      "‚úì Training data shape: (97484, 67)\n",
      "‚úì Testing  data shape: (24372, 67)\n",
      "‚úì Target distribution:\n",
      "  - No Default (0): 89,608 (91.9%)\n",
      "  - Default (1): 7,876 (8.1%)\n",
      "‚úì Imbalance ratio: 11.4:1\n",
      "\n",
      "‚öñÔ∏è Calculated scale_pos_weight: 11.38\n",
      "‚öñÔ∏è Using scale_pos_weight: 11.38\n",
      "\n",
      "====================================================================================================\n",
      "üìä PERFORMING K-FOLD CROSS VALIDATION\n",
      "====================================================================================================\n",
      "\n",
      "üîÑ Cross-validating Logistic Regression...\n",
      "  ‚úì AUC-ROC: 0.7361 (+/- 0.0053)\n",
      "  ‚úì Recall: 0.6705 (+/- 0.0148)\n",
      "  ‚úì F1-Score: 0.2512 (+/- 0.0049)\n",
      "\n",
      "üîÑ Cross-validating XGBoost...\n",
      "  ‚úì AUC-ROC: 0.7674 (+/- 0.0039)\n",
      "  ‚úì Recall: 0.5500 (+/- 0.0141)\n",
      "  ‚úì F1-Score: 0.3109 (+/- 0.0058)\n",
      "\n",
      "üîÑ Cross-validating LightGBM...\n",
      "  ‚úì AUC-ROC: 0.7643 (+/- 0.0054)\n",
      "  ‚úì Recall: 0.5978 (+/- 0.0130)\n",
      "  ‚úì F1-Score: 0.2966 (+/- 0.0043)\n",
      "\n",
      "====================================================================================================\n",
      "üöÄ TRAINING FINAL MODELS\n",
      "====================================================================================================\n",
      "\n",
      "==================================================\n",
      "Training Logistic Regression\n",
      "==================================================\n",
      "\n",
      "üìä Model Performance:\n",
      "  AUC-ROC: 0.7330\n",
      "  AUC-PR: 0.2016\n",
      "\n",
      "üìä Standard Threshold (0.5):\n",
      "  Recall: 67.34%\n",
      "  Precision: 15.52%\n",
      "  F1-Score: 0.2523\n",
      "  Defaults Missed: 643\n",
      "  Total Cost: $209,763,000\n",
      "\n",
      "üìä Optimal Threshold (0.000):\n",
      "  Recall: 100.00%\n",
      "  Precision: 8.08%\n",
      "  F1-Score: 0.1495\n",
      "  Defaults Missed: 0\n",
      "  Total Cost: $22,402,000\n",
      "  Net Savings: $597,833,000\n",
      "  ROI: 2668.7%\n",
      "\n",
      "üîç Performing SHAP analysis for Logistic Regression...\n",
      "‚úì SHAP analysis complete for Logistic Regression\n",
      "  Top 5 features: Score_Source_3, Score_Source_2, Score_Source_3_Available, Score_Source_1, Num_Credit_Scores_Available\n",
      "\n",
      "==================================================\n",
      "Training XGBoost\n",
      "==================================================\n",
      "\n",
      "üìä Model Performance:\n",
      "  AUC-ROC: 0.7672\n",
      "  AUC-PR: 0.2505\n",
      "\n",
      "üìä Standard Threshold (0.5):\n",
      "  Recall: 57.95%\n",
      "  Precision: 21.08%\n",
      "  F1-Score: 0.3091\n",
      "  Defaults Missed: 828\n",
      "  Total Cost: $265,092,000\n",
      "\n",
      "üìä Optimal Threshold (0.003):\n",
      "  Recall: 100.00%\n",
      "  Precision: 8.08%\n",
      "  F1-Score: 0.1495\n",
      "  Defaults Missed: 0\n",
      "  Total Cost: $22,400,000\n",
      "  Net Savings: $597,835,000\n",
      "  ROI: 2668.9%\n",
      "\n",
      "üîç Performing SHAP analysis for XGBoost...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '[5E-1]'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 510\u001b[0m\n\u001b[0;32m    507\u001b[0m     trained_models[name] \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;66;03m# Perform SHAP analysis\u001b[39;00m\n\u001b[1;32m--> 510\u001b[0m     \u001b[43mperform_shap_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# =====================================================================\u001b[39;00m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;66;03m# STEP 5: MODEL CALIBRATION\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;66;03m# =====================================================================\u001b[39;00m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "Cell \u001b[1;32mIn[16], line 305\u001b[0m, in \u001b[0;36mperform_shap_analysis\u001b[1;34m(model, X_train, X_test, model_name, sample_size)\u001b[0m\n\u001b[0;32m    302\u001b[0m     shap_values \u001b[38;5;241m=\u001b[39m explainer\u001b[38;5;241m.\u001b[39mshap_values(X_test)\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;66;03m# For tree-based models\u001b[39;00m\n\u001b[1;32m--> 305\u001b[0m     explainer \u001b[38;5;241m=\u001b[39m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTreeExplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    306\u001b[0m     shap_values \u001b[38;5;241m=\u001b[39m explainer\u001b[38;5;241m.\u001b[39mshap_values(X_test)\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(shap_values, \u001b[38;5;28mlist\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\MoorthyMitturu\\OneDrive - Aionos\\Documents\\PublicSapient\\.venv\\lib\\site-packages\\shap\\explainers\\_tree.py:278\u001b[0m, in \u001b[0;36mTreeExplainer.__init__\u001b[1;34m(self, model, data, model_output, feature_perturbation, feature_names, approximate, link, linearize_link)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_perturbation \u001b[38;5;241m=\u001b[39m feature_perturbation\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpected_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 278\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mTreeEnsemble\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_missing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_output \u001b[38;5;241m=\u001b[39m model_output\n\u001b[0;32m    280\u001b[0m \u001b[38;5;66;03m# self.model_output = self.model.model_output # this allows the TreeEnsemble to translate model outputs types by how it loads the model\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \n\u001b[0;32m    282\u001b[0m \u001b[38;5;66;03m# check for unsupported combinations of feature_perturbation and model_outputs\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MoorthyMitturu\\OneDrive - Aionos\\Documents\\PublicSapient\\.venv\\lib\\site-packages\\shap\\explainers\\_tree.py:1261\u001b[0m, in \u001b[0;36mTreeEnsemble.__init__\u001b[1;34m(self, model, data, data_missing, model_output)\u001b[0m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32\n\u001b[0;32m   1260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moriginal_model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_booster()\n\u001b[1;32m-> 1261\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_xgboost_model_attributes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_missing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjective_name_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtree_output_name_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1266\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_output \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_stacked_models \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1270\u001b[0m         \u001b[38;5;66;03m# with predict_proba we need to double the outputs to match\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MoorthyMitturu\\OneDrive - Aionos\\Documents\\PublicSapient\\.venv\\lib\\site-packages\\shap\\explainers\\_tree.py:1506\u001b[0m, in \u001b[0;36mTreeEnsemble._set_xgboost_model_attributes\u001b[1;34m(self, data, data_missing, objective_name_map, tree_output_name_map)\u001b[0m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_set_xgboost_model_attributes\u001b[39m(\n\u001b[0;32m   1499\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1500\u001b[0m     data,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1503\u001b[0m     tree_output_name_map,\n\u001b[0;32m   1504\u001b[0m ):\n\u001b[0;32m   1505\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxgboost\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1506\u001b[0m     loader \u001b[38;5;241m=\u001b[39m \u001b[43mXGBTreeModelLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moriginal_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1508\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrees \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mget_trees(data\u001b[38;5;241m=\u001b[39mdata, data_missing\u001b[38;5;241m=\u001b[39mdata_missing)\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_offset \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mbase_score\n",
      "File \u001b[1;32mc:\\Users\\MoorthyMitturu\\OneDrive - Aionos\\Documents\\PublicSapient\\.venv\\lib\\site-packages\\shap\\explainers\\_tree.py:2104\u001b[0m, in \u001b[0;36mXGBTreeModelLoader.__init__\u001b[1;34m(self, xgb_model)\u001b[0m\n\u001b[0;32m   2102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_trees_per_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(diff[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   2103\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_targets \u001b[38;5;241m=\u001b[39m n_targets\n\u001b[1;32m-> 2104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlearner_model_param\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbase_score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2105\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_trees_per_iter \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   2107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname_obj \u001b[38;5;241m=\u001b[39m objective[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '[5E-1]'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Enhanced Loan Default Prediction Training Pipeline\n",
    "=================================================\n",
    "This pipeline includes:\n",
    "- K-Fold Cross Validation\n",
    "- SHAP feature importance analysis\n",
    "- Threshold optimization\n",
    "- Model calibration\n",
    "- Business metrics\n",
    "- Early stopping for boosting models\n",
    "\n",
    "Author: Data Science Team\n",
    "Date: November 2025\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, precision_recall_curve, auc,\n",
    "    classification_report, confusion_matrix,\n",
    "    roc_curve, f1_score,\n",
    "    make_scorer\n",
    ")\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold, cross_val_score,\n",
    "    cross_validate\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"üè¶ ENHANCED LOAN DEFAULT PREDICTION - MODEL TRAINING PIPELINE\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# =====================================================================\n",
    "# CONFIGURATION\n",
    "# =====================================================================\n",
    "RANDOM_SEED = 42\n",
    "N_FOLDS = 5\n",
    "DEFAULT_COST = 315000  # Cost of missed default\n",
    "INVESTIGATION_COST = 1000  # Cost to investigate flagged loan\n",
    "EARLY_STOPPING_ROUNDS = 50\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(\"artifacts/models\", exist_ok=True)\n",
    "os.makedirs(\"artifacts/reports\", exist_ok=True)\n",
    "os.makedirs(\"artifacts/plots\", exist_ok=True)\n",
    "os.makedirs(\"artifacts/shap\", exist_ok=True)\n",
    "\n",
    "# =====================================================================\n",
    "# STEP 1: LOAD ENCODED DATA\n",
    "# =====================================================================\n",
    "print(\"\\nüì• Loading encoded data...\")\n",
    "\n",
    "X_train = pd.read_csv('processed_data/X_train_encoded.csv')\n",
    "X_test = pd.read_csv('processed_data/X_test_encoded.csv')\n",
    "y_train = pd.read_csv('processed_data/y_train.csv').values.ravel() # ravel It is used to return a flattened, one-dimensional view of the underlying data as a NumPy ndarray\n",
    "y_test = pd.read_csv('processed_data/y_test.csv').values.ravel()\n",
    "\n",
    "print(f\"‚úì Training data shape: {X_train.shape}\")\n",
    "print(f\"‚úì Testing  data shape: {X_test.shape}\")\n",
    "print(f\"‚úì Target distribution:\")\n",
    "print(f\"  - No Default (0): {(y_train==0).sum():,} ({(y_train==0).sum()/len(y_train):.1%})\")\n",
    "print(f\"  - Default (1): {(y_train==1).sum():,} ({(y_train==1).sum()/len(y_train):.1%})\")\n",
    "print(f\"‚úì Imbalance ratio: {(y_train==0).sum() / (y_train==1).sum():.1f}:1\")\n",
    "\n",
    "# =====================================================================\n",
    "# STEP 2: MODEL CONFIGURATION\n",
    "# =====================================================================\n",
    "# Calculate actual scale_pos_weight from data\n",
    "calculated_scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"\\n‚öñÔ∏è Calculated scale_pos_weight: {calculated_scale_pos_weight:.2f}\")\n",
    "\n",
    "# You can adjust this based on business requirements\n",
    "# Higher values = fewer false negatives (missed defaults)\n",
    "# Lower values = fewer false positives (unnecessary investigations)\n",
    "SCALE_POS_WEIGHT = calculated_scale_pos_weight  # Use actual imbalance ratio\n",
    "\n",
    "print(f\"‚öñÔ∏è Using scale_pos_weight: {SCALE_POS_WEIGHT:.2f}\")\n",
    "\n",
    "models_config = {\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        class_weight='balanced',\n",
    "        max_iter=1000,\n",
    "        random_state=RANDOM_SEED,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        scale_pos_weight=SCALE_POS_WEIGHT,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        n_estimators=500,\n",
    "        min_child_weight=1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        gamma=0,\n",
    "        random_state=RANDOM_SEED,\n",
    "        eval_metric='auc',\n",
    "        early_stopping_rounds=None,\n",
    "        n_jobs=-1,\n",
    "        verbosity=0\n",
    "    ),\n",
    "    \"LightGBM\": LGBMClassifier(\n",
    "        scale_pos_weight=SCALE_POS_WEIGHT,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        n_estimators=500,\n",
    "        num_leaves=31,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=RANDOM_SEED,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1,\n",
    "        metric='auc',\n",
    "        early_stopping_rounds=None\n",
    "    )\n",
    "}\n",
    "\n",
    "# =====================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# =====================================================================\n",
    "\n",
    "def find_optimal_threshold(y_true, y_scores, metric='f1'):\n",
    "    \"\"\"\n",
    "    Find optimal threshold for classification.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_true : array-like\n",
    "        True labels\n",
    "    y_scores : array-like\n",
    "        Predicted probabilities\n",
    "    metric : str\n",
    "        Metric to optimize ('f1', 'business', 'balanced')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    optimal_threshold : float\n",
    "        Best threshold value\n",
    "    best_score : float\n",
    "        Best score achieved\n",
    "    \"\"\"\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_scores)\n",
    "    \n",
    "    if metric == 'f1':\n",
    "        # Optimize F1 score\n",
    "        f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "        best_idx = np.argmax(f1_scores[:-1])  # Exclude last point\n",
    "        return thresholds[best_idx], f1_scores[best_idx]\n",
    "    \n",
    "    elif metric == 'business':\n",
    "        # Optimize based on business costs\n",
    "        best_cost = float('inf')\n",
    "        best_threshold = 0.5\n",
    "        \n",
    "        for threshold in thresholds:\n",
    "            y_pred = (y_scores >= threshold).astype(int)\n",
    "            cm = confusion_matrix(y_true, y_pred)\n",
    "            \n",
    "            false_negatives = cm[1,0] if cm.shape[0] > 1 else 0\n",
    "            false_positives = cm[0,1] if cm.shape[0] > 1 else 0\n",
    "            \n",
    "            total_cost = (false_negatives * DEFAULT_COST) + (false_positives * INVESTIGATION_COST)\n",
    "            \n",
    "            if total_cost < best_cost:\n",
    "                best_cost = total_cost\n",
    "                best_threshold = threshold\n",
    "        \n",
    "        return best_threshold, -best_cost  # Return negative cost as score\n",
    "    \n",
    "    else:  # balanced\n",
    "        # Balance between precision and recall\n",
    "        f_scores = (1 + 0.5**2) * (precision * recall) / (0.5**2 * precision + recall + 1e-8)\n",
    "        best_idx = np.argmax(f_scores[:-1])\n",
    "        return thresholds[best_idx], f_scores[best_idx]\n",
    "\n",
    "\n",
    "def calculate_business_metrics(y_true, y_pred, y_scores=None):\n",
    "    \"\"\"Calculate business-focused metrics.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    if cm.shape[0] > 1:\n",
    "        true_negatives = cm[0,0]\n",
    "        false_positives = cm[0,1]\n",
    "        false_negatives = cm[1,0]\n",
    "        true_positives = cm[1,1]\n",
    "    else:\n",
    "        # Handle edge case where only one class is predicted\n",
    "        true_negatives = cm[0,0] if y_pred[0] == 0 else 0\n",
    "        false_positives = false_negatives = true_positives = 0\n",
    "    \n",
    "    # Calculate costs\n",
    "    default_loss = false_negatives * DEFAULT_COST\n",
    "    investigation_cost = false_positives * INVESTIGATION_COST\n",
    "    total_cost = default_loss + investigation_cost\n",
    "    \n",
    "    # Calculate savings (defaults prevented)\n",
    "    defaults_prevented = true_positives\n",
    "    potential_savings = defaults_prevented * DEFAULT_COST\n",
    "    net_savings = potential_savings - investigation_cost\n",
    "    \n",
    "    metrics = {\n",
    "        'defaults_missed': false_negatives,\n",
    "        'false_alarms': false_positives,\n",
    "        'defaults_caught': true_positives,\n",
    "        'default_loss': default_loss,\n",
    "        'investigation_cost': investigation_cost,\n",
    "        'total_cost': total_cost,\n",
    "        'potential_savings': potential_savings,\n",
    "        'net_savings': net_savings,\n",
    "        'roi': (net_savings / investigation_cost * 100) if investigation_cost > 0 else 0\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def plot_calibration_curve(y_true, probas_dict, save_path):\n",
    "    \"\"\"Plot calibration curves for multiple models.\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    for name, y_prob in probas_dict.items():\n",
    "        fraction_true, fraction_pred = calibration_curve(y_true, y_prob, n_bins=10)\n",
    "        plt.plot(fraction_pred, fraction_true, marker='o', linewidth=2, label=name)\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfectly calibrated')\n",
    "    plt.xlabel('Mean Predicted Probability', fontsize=12)\n",
    "    plt.ylabel('Fraction of Positives', fontsize=12)\n",
    "    plt.title('Calibration Curves - Model Reliability', fontsize=14)\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_roc_curves(y_true, probas_dict, save_path):\n",
    "    \"\"\"Plot ROC curves for multiple models.\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    for name, y_prob in probas_dict.items():\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "        auc_score = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, linewidth=2, label=f'{name} (AUC = {auc_score:.3f})')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random')\n",
    "    plt.xlabel('False Positive Rate', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate', fontsize=12)\n",
    "    plt.title('ROC Curves - Model Performance', fontsize=14)\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def perform_shap_analysis(model, X_train, X_test, model_name, sample_size=1000):\n",
    "    \"\"\"\n",
    "    Perform SHAP analysis for feature importance.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : fitted model\n",
    "        The trained model\n",
    "    X_train : pd.DataFrame\n",
    "        Training data\n",
    "    X_test : pd.DataFrame\n",
    "        Test data\n",
    "    model_name : str\n",
    "        Name of the model\n",
    "    sample_size : int\n",
    "        Number of samples to use for SHAP (for speed)\n",
    "    \"\"\"\n",
    "    print(f\"\\nüîç Performing SHAP analysis for {model_name}...\")\n",
    "    \n",
    "    # Sample data for faster computation\n",
    "    if X_train.shape[0] > sample_size:\n",
    "        sample_idx = np.random.choice(X_train.index, sample_size, replace=False)\n",
    "        X_sample = X_train.loc[sample_idx]\n",
    "    else:\n",
    "        X_sample = X_train\n",
    "    \n",
    "    # Create SHAP explainer\n",
    "    if model_name == \"Logistic Regression\":\n",
    "        explainer = shap.LinearExplainer(model, X_sample)\n",
    "        shap_values = explainer.shap_values(X_test)\n",
    "    else:\n",
    "        # For tree-based models\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        shap_values = explainer.shap_values(X_test)\n",
    "        if isinstance(shap_values, list):\n",
    "            shap_values = shap_values[1]  # For binary classification, use positive class\n",
    "    \n",
    "    # Save SHAP summary plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    shap.summary_plot(shap_values, X_test, show=False, max_display=20)\n",
    "    plt.title(f'SHAP Summary Plot - {model_name}', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'artifacts/shap/{model_name.lower().replace(\" \", \"_\")}_summary.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Calculate and save feature importance\n",
    "    shap_importance = np.abs(shap_values).mean(axis=0)\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X_test.columns,\n",
    "        'shap_importance': shap_importance\n",
    "    }).sort_values('shap_importance', ascending=False)\n",
    "    \n",
    "    # Save top 20 features plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    top_features = feature_importance.head(20)\n",
    "    plt.barh(range(len(top_features)), top_features['shap_importance'])\n",
    "    plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "    plt.xlabel('Mean |SHAP value|', fontsize=12)\n",
    "    plt.title(f'Top 20 Features - {model_name}', fontsize=14)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'artifacts/shap/{model_name.lower().replace(\" \", \"_\")}_importance.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Save feature importance to CSV\n",
    "    feature_importance.to_csv(\n",
    "        f'artifacts/reports/{model_name.lower().replace(\" \", \"_\")}_feature_importance.csv', \n",
    "        index=False\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úì SHAP analysis complete for {model_name}\")\n",
    "    print(f\"  Top 5 features: {', '.join(feature_importance.head(5)['feature'].tolist())}\")\n",
    "    \n",
    "    return feature_importance\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# STEP 3: K-FOLD CROSS VALIDATION\n",
    "# =====================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üìä PERFORMING K-FOLD CROSS VALIDATION\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Define stratified k-fold\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "# Define scoring metrics\n",
    "scoring = {\n",
    "    'roc_auc': 'roc_auc',\n",
    "    'precision': make_scorer(lambda y_true, y_pred: \n",
    "                           classification_report(y_true, y_pred, output_dict=True)['1']['precision']),\n",
    "    'recall': make_scorer(lambda y_true, y_pred: \n",
    "                        classification_report(y_true, y_pred, output_dict=True)['1']['recall']),\n",
    "    'f1': make_scorer(f1_score, pos_label=1)\n",
    "}\n",
    "\n",
    "cv_results = {}\n",
    "\n",
    "for name, model in models_config.items():\n",
    "    print(f\"\\nüîÑ Cross-validating {name}...\")\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_validate(\n",
    "        model, X_train, y_train, \n",
    "        cv=skf, \n",
    "        scoring=scoring,\n",
    "        n_jobs=-1,\n",
    "        return_train_score=False\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    cv_results[name] = {\n",
    "        'auc_mean': cv_scores['test_roc_auc'].mean(),\n",
    "        'auc_std': cv_scores['test_roc_auc'].std(),\n",
    "        'precision_mean': cv_scores['test_precision'].mean(),\n",
    "        'precision_std': cv_scores['test_precision'].std(),\n",
    "        'recall_mean': cv_scores['test_recall'].mean(),\n",
    "        'recall_std': cv_scores['test_recall'].std(),\n",
    "        'f1_mean': cv_scores['test_f1'].mean(),\n",
    "        'f1_std': cv_scores['test_f1'].std()\n",
    "    }\n",
    "    \n",
    "    print(f\"  ‚úì AUC-ROC: {cv_results[name]['auc_mean']:.4f} (+/- {cv_results[name]['auc_std']:.4f})\")\n",
    "    print(f\"  ‚úì Recall: {cv_results[name]['recall_mean']:.4f} (+/- {cv_results[name]['recall_std']:.4f})\")\n",
    "    print(f\"  ‚úì F1-Score: {cv_results[name]['f1_mean']:.4f} (+/- {cv_results[name]['f1_std']:.4f})\")\n",
    "\n",
    "# Save CV results\n",
    "cv_df = pd.DataFrame(cv_results).T\n",
    "cv_df.to_csv('artifacts/reports/cross_validation_results.csv')\n",
    "\n",
    "# =====================================================================\n",
    "# STEP 4: FINAL MODEL TRAINING AND EVALUATION\n",
    "# =====================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üöÄ TRAINING FINAL MODELS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "results = []\n",
    "trained_models = {}\n",
    "probas_dict = {}\n",
    "\n",
    "for name, model in models_config.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training {name}\")\n",
    "    print('='*50)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Handle early stopping for boosting models\n",
    "    if name in ['XGBoost', 'LightGBM']:\n",
    "        eval_set = [(X_test, y_test)]\n",
    "        model.fit(X_train, y_train, eval_set=eval_set, verbose=False)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    probas_dict[name] = y_pred_proba\n",
    "    \n",
    "    # Find optimal thresholds\n",
    "    threshold_f1, best_f1 = find_optimal_threshold(y_test, y_pred_proba, metric='f1')\n",
    "    threshold_business, best_business = find_optimal_threshold(y_test, y_pred_proba, metric='business')\n",
    "    \n",
    "    # Use business-optimized threshold\n",
    "    optimal_threshold = threshold_business\n",
    "    y_pred_optimal = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "    \n",
    "    # Standard threshold predictions for comparison\n",
    "    y_pred_standard = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "    \n",
    "    # Classification reports\n",
    "    report_standard = classification_report(y_test, y_pred_standard, output_dict=True)\n",
    "    report_optimal = classification_report(y_test, y_pred_optimal, output_dict=True)\n",
    "    \n",
    "    # Business metrics\n",
    "    business_metrics_standard = calculate_business_metrics(y_test, y_pred_standard, y_pred_proba)\n",
    "    business_metrics_optimal = calculate_business_metrics(y_test, y_pred_optimal, y_pred_proba)\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"AUC-ROC\": auc_roc,\n",
    "        \"AUC-PR\": auc_pr,\n",
    "        \"CV_AUC_Mean\": cv_results[name]['auc_mean'],\n",
    "        \"CV_AUC_Std\": cv_results[name]['auc_std'],\n",
    "        \"Recall_Standard\": report_standard['1']['recall'],\n",
    "        \"Precision_Standard\": report_standard['1']['precision'],\n",
    "        \"F1_Standard\": report_standard['1']['f1-score'],\n",
    "        \"Recall_Optimal\": report_optimal['1']['recall'],\n",
    "        \"Precision_Optimal\": report_optimal['1']['precision'],\n",
    "        \"F1_Optimal\": report_optimal['1']['f1-score'],\n",
    "        \"Optimal_Threshold\": optimal_threshold,\n",
    "        \"Defaults_Missed_Standard\": business_metrics_standard['defaults_missed'],\n",
    "        \"Defaults_Missed_Optimal\": business_metrics_optimal['defaults_missed'],\n",
    "        \"Total_Cost_Standard\": business_metrics_standard['total_cost'],\n",
    "        \"Total_Cost_Optimal\": business_metrics_optimal['total_cost'],\n",
    "        \"Net_Savings_Optimal\": business_metrics_optimal['net_savings'],\n",
    "        \"ROI_Optimal\": business_metrics_optimal['roi'],\n",
    "        \"Training_Time\": training_time\n",
    "    })\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\nüìä Model Performance:\")\n",
    "    print(f\"  AUC-ROC: {auc_roc:.4f}\")\n",
    "    print(f\"  AUC-PR: {auc_pr:.4f}\")\n",
    "    \n",
    "    print(f\"\\nüìä Standard Threshold (0.5):\")\n",
    "    print(f\"  Recall: {report_standard['1']['recall']:.2%}\")\n",
    "    print(f\"  Precision: {report_standard['1']['precision']:.2%}\")\n",
    "    print(f\"  F1-Score: {report_standard['1']['f1-score']:.4f}\")\n",
    "    print(f\"  Defaults Missed: {business_metrics_standard['defaults_missed']:,}\")\n",
    "    print(f\"  Total Cost: ${business_metrics_standard['total_cost']:,.0f}\")\n",
    "    \n",
    "    print(f\"\\nüìä Optimal Threshold ({optimal_threshold:.3f}):\")\n",
    "    print(f\"  Recall: {report_optimal['1']['recall']:.2%}\")\n",
    "    print(f\"  Precision: {report_optimal['1']['precision']:.2%}\")\n",
    "    print(f\"  F1-Score: {report_optimal['1']['f1-score']:.4f}\")\n",
    "    print(f\"  Defaults Missed: {business_metrics_optimal['defaults_missed']:,}\")\n",
    "    print(f\"  Total Cost: ${business_metrics_optimal['total_cost']:,.0f}\")\n",
    "    print(f\"  Net Savings: ${business_metrics_optimal['net_savings']:,.0f}\")\n",
    "    print(f\"  ROI: {business_metrics_optimal['roi']:.1f}%\")\n",
    "    \n",
    "    # Store model with optimal threshold\n",
    "    model.optimal_threshold = optimal_threshold\n",
    "    trained_models[name] = model\n",
    "    \n",
    "    # Perform SHAP analysis\n",
    "    perform_shap_analysis(model, X_train, X_test, name)\n",
    "\n",
    "# =====================================================================\n",
    "# STEP 5: MODEL CALIBRATION\n",
    "# =====================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üéØ CALIBRATING MODELS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "calibrated_models = {}\n",
    "calibrated_probas = {}\n",
    "\n",
    "for name, model in trained_models.items():\n",
    "    print(f\"\\nCalibrating {name}...\")\n",
    "    \n",
    "    # Calibrate model using isotonic regression\n",
    "    calibrated = CalibratedClassifierCV(model, method='isotonic', cv=3)\n",
    "    calibrated.fit(X_train, y_train)\n",
    "    \n",
    "    # Get calibrated probabilities\n",
    "    calibrated_proba = calibrated.predict_proba(X_test)[:, 1]\n",
    "    calibrated_probas[name] = calibrated_proba\n",
    "    \n",
    "    # Compare calibration\n",
    "    original_score = roc_auc_score(y_test, probas_dict[name])\n",
    "    calibrated_score = roc_auc_score(y_test, calibrated_proba)\n",
    "    \n",
    "    print(f\"  Original AUC: {original_score:.4f}\")\n",
    "    print(f\"  Calibrated AUC: {calibrated_score:.4f}\")\n",
    "    print(f\"  Improvement: {calibrated_score - original_score:+.4f}\")\n",
    "    \n",
    "    calibrated_models[name] = calibrated\n",
    "\n",
    "# =====================================================================\n",
    "# STEP 6: GENERATE VISUALIZATIONS\n",
    "# =====================================================================\n",
    "print(\"\\nüìà Generating visualizations...\")\n",
    "\n",
    "# Plot calibration curves\n",
    "plot_calibration_curve(y_test, probas_dict, 'artifacts/plots/calibration_curves.png')\n",
    "plot_calibration_curve(y_test, calibrated_probas, 'artifacts/plots/calibration_curves_calibrated.png')\n",
    "\n",
    "# Plot ROC curves\n",
    "plot_roc_curves(y_test, probas_dict, 'artifacts/plots/roc_curves.png')\n",
    "\n",
    "# Plot model comparison\n",
    "results_df = pd.DataFrame(results)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# AUC comparison\n",
    "ax = axes[0, 0]\n",
    "results_df.plot(x='Model', y=['AUC-ROC', 'AUC-PR'], kind='bar', ax=ax)\n",
    "ax.set_title('Model Performance - AUC Scores', fontsize=14)\n",
    "ax.set_ylabel('Score')\n",
    "ax.legend(['AUC-ROC', 'AUC-PR'])\n",
    "ax.set_ylim([0, 1])\n",
    "\n",
    "# Cost comparison\n",
    "ax = axes[0, 1]\n",
    "cost_data = results_df[['Model', 'Total_Cost_Standard', 'Total_Cost_Optimal']].set_index('Model')\n",
    "cost_data.plot(kind='bar', ax=ax)\n",
    "ax.set_title('Total Cost Comparison', fontsize=14)\n",
    "ax.set_ylabel('Cost ($)')\n",
    "ax.legend(['Standard Threshold', 'Optimal Threshold'])\n",
    "\n",
    "# Defaults missed comparison\n",
    "ax = axes[1, 0]\n",
    "defaults_data = results_df[['Model', 'Defaults_Missed_Standard', 'Defaults_Missed_Optimal']].set_index('Model')\n",
    "defaults_data.plot(kind='bar', ax=ax)\n",
    "ax.set_title('Defaults Missed Comparison', fontsize=14)\n",
    "ax.set_ylabel('Count')\n",
    "ax.legend(['Standard Threshold', 'Optimal Threshold'])\n",
    "\n",
    "# ROI comparison\n",
    "ax = axes[1, 1]\n",
    "results_df.plot(x='Model', y='ROI_Optimal', kind='bar', ax=ax, legend=False)\n",
    "ax.set_title('Return on Investment (Optimal Threshold)', fontsize=14)\n",
    "ax.set_ylabel('ROI (%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/plots/model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# =====================================================================\n",
    "# STEP 7: SAVE MODELS AND RESULTS\n",
    "# =====================================================================\n",
    "print(\"\\nüíæ Saving models and results...\")\n",
    "\n",
    "# Save models\n",
    "for name, model in trained_models.items():\n",
    "    model_path = f\"artifacts/models/{name.replace(' ', '_').lower()}.pkl\"\n",
    "    joblib.dump(model, model_path)\n",
    "    print(f\"  ‚úì Saved {name} ‚Üí {model_path}\")\n",
    "\n",
    "# Save calibrated models\n",
    "for name, model in calibrated_models.items():\n",
    "    model_path = f\"artifacts/models/{name.replace(' ', '_').lower()}_calibrated.pkl\"\n",
    "    joblib.dump(model, model_path)\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv(\"artifacts/reports/model_results_enhanced.csv\", index=False)\n",
    "cv_df.to_csv(\"artifacts/reports/cross_validation_results.csv\")\n",
    "\n",
    "# Save optimal thresholds\n",
    "thresholds_df = pd.DataFrame([\n",
    "    {\n",
    "        'Model': name, \n",
    "        'Optimal_Threshold': model.optimal_threshold,\n",
    "        'Metric_Optimized': 'business_cost'\n",
    "    } \n",
    "    for name, model in trained_models.items()\n",
    "])\n",
    "thresholds_df.to_csv(\"artifacts/reports/optimal_thresholds.csv\", index=False)\n",
    "\n",
    "# =====================================================================\n",
    "# STEP 8: GENERATE FINAL REPORT\n",
    "# =====================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üìä FINAL MODEL COMPARISON REPORT\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Sort by net savings\n",
    "results_df_sorted = results_df.sort_values('Net_Savings_Optimal', ascending=False)\n",
    "\n",
    "print(\"\\nüèÜ Model Rankings by Net Savings:\")\n",
    "for idx, row in results_df_sorted.iterrows():\n",
    "    print(f\"\\n{idx+1}. {row['Model']}\")\n",
    "    print(f\"   Net Savings: ${row['Net_Savings_Optimal']:,.0f}\")\n",
    "    print(f\"   ROI: {row['ROI_Optimal']:.1f}%\")\n",
    "    print(f\"   AUC-ROC: {row['AUC-ROC']:.4f} (CV: {row['CV_AUC_Mean']:.4f} ¬± {row['CV_AUC_Std']:.4f})\")\n",
    "    print(f\"   Optimal Threshold: {row['Optimal_Threshold']:.3f}\")\n",
    "    print(f\"   Cost Reduction: ${row['Total_Cost_Standard'] - row['Total_Cost_Optimal']:,.0f}\")\n",
    "\n",
    "best_model = results_df_sorted.iloc[0]\n",
    "print(f\"\\nüéØ RECOMMENDED MODEL: {best_model['Model']}\")\n",
    "print(f\"   Expected Annual Savings: ${best_model['Net_Savings_Optimal'] * 12:,.0f}\")\n",
    "print(f\"   Defaults Caught: {(best_model['Recall_Optimal'] * 100):.1f}%\")\n",
    "print(f\"   False Alarm Rate: {(1 - best_model['Precision_Optimal']) * 100:.1f}%\")\n",
    "\n",
    "# Create executive summary\n",
    "summary = {\n",
    "    'Best_Model': best_model['Model'],\n",
    "    'Annual_Savings': best_model['Net_Savings_Optimal'] * 12,\n",
    "    'ROI': best_model['ROI_Optimal'],\n",
    "    'Defaults_Prevented_Rate': best_model['Recall_Optimal'] * 100,\n",
    "    'Investigation_Accuracy': best_model['Precision_Optimal'] * 100,\n",
    "    'Optimal_Threshold': best_model['Optimal_Threshold'],\n",
    "    'Implementation_Recommendation': 'Deploy with continuous monitoring and monthly recalibration'\n",
    "}\n",
    "\n",
    "pd.DataFrame([summary]).to_csv('artifacts/reports/executive_summary.csv', index=False)\n",
    "\n",
    "print(\"\\n‚úÖ Enhanced training pipeline completed successfully!\")\n",
    "print(f\"üìÅ All artifacts saved in 'artifacts/' directory\")\n",
    "print(f\"üìä Check 'artifacts/shap/' for feature importance visualizations\")\n",
    "print(f\"üìà Check 'artifacts/plots/' for performance visualizations\")\n",
    "print(f\"üìã Check 'artifacts/reports/' for detailed reports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "573bc72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "üè¶ ENHANCED LOAN DEFAULT PREDICTION - MODEL TRAINING PIPELINE\n",
      "====================================================================================================\n",
      "\n",
      "üì• Loading encoded data...\n",
      "‚úì Training data shape: (97484, 67)\n",
      "‚úì Testing  data shape: (24372, 67)\n",
      "‚úì Target distribution:\n",
      "  - No Default (0): 89,608 (91.9%)\n",
      "  - Default (1): 7,876 (8.1%)\n",
      "‚úì Imbalance ratio: 11.4:1\n",
      "\n",
      "‚öñÔ∏è Calculated scale_pos_weight: 11.38\n",
      "‚öñÔ∏è Using scale_pos_weight: 11.38\n",
      "\n",
      "====================================================================================================\n",
      "üìä PERFORMING K-FOLD CROSS VALIDATION\n",
      "====================================================================================================\n",
      "\n",
      "üîÑ Cross-validating Logistic Regression...\n",
      "  ‚úì AUC-ROC: 0.7361 (+/- 0.0053)\n",
      "  ‚úì Recall: 0.6705 (+/- 0.0148)\n",
      "  ‚úì F1-Score: 0.2512 (+/- 0.0049)\n",
      "\n",
      "üîÑ Cross-validating XGBoost...\n",
      "  ‚úì AUC-ROC: 0.7674 (+/- 0.0039)\n",
      "  ‚úì Recall: 0.5500 (+/- 0.0141)\n",
      "  ‚úì F1-Score: 0.3109 (+/- 0.0058)\n",
      "\n",
      "üîÑ Cross-validating LightGBM...\n",
      "  ‚úì AUC-ROC: 0.7643 (+/- 0.0054)\n",
      "  ‚úì Recall: 0.5978 (+/- 0.0130)\n",
      "  ‚úì F1-Score: 0.2966 (+/- 0.0043)\n",
      "\n",
      "====================================================================================================\n",
      "üöÄ TRAINING FINAL MODELS\n",
      "====================================================================================================\n",
      "\n",
      "==================================================\n",
      "Training Logistic Regression\n",
      "==================================================\n",
      "\n",
      "üìä Model Performance:\n",
      "  AUC-ROC: 0.7330\n",
      "  AUC-PR: 0.2016\n",
      "\n",
      "üìä Standard Threshold (0.5):\n",
      "  Recall: 67.34%\n",
      "  Precision: 15.52%\n",
      "  F1-Score: 0.2523\n",
      "  Defaults Missed: 643\n",
      "  Total Cost: $209,763,000\n",
      "\n",
      "üìä Optimal Threshold (0.000):\n",
      "  Recall: 100.00%\n",
      "  Precision: 8.08%\n",
      "  F1-Score: 0.1495\n",
      "  Defaults Missed: 0\n",
      "  Total Cost: $22,402,000\n",
      "  Net Savings: $597,833,000\n",
      "  ROI: 2668.7%\n",
      "\n",
      "üîç Performing SHAP analysis for Logistic Regression...\n",
      "  ‚úì SHAP analysis complete for Logistic Regression\n",
      "  Top 5 features: Score_Source_3, Score_Source_2, Score_Source_3_Available, Score_Source_1, Num_Credit_Scores_Available\n",
      "\n",
      "==================================================\n",
      "Training XGBoost\n",
      "==================================================\n",
      "[0]\tvalidation_0-auc:0.66909\n",
      "[1]\tvalidation_0-auc:0.67880\n",
      "[2]\tvalidation_0-auc:0.68709\n",
      "[3]\tvalidation_0-auc:0.70372\n",
      "[4]\tvalidation_0-auc:0.71093\n",
      "[5]\tvalidation_0-auc:0.71676\n",
      "[6]\tvalidation_0-auc:0.72098\n",
      "[7]\tvalidation_0-auc:0.72245\n",
      "[8]\tvalidation_0-auc:0.72391\n",
      "[9]\tvalidation_0-auc:0.72439\n",
      "[10]\tvalidation_0-auc:0.72483\n",
      "[11]\tvalidation_0-auc:0.72547\n",
      "[12]\tvalidation_0-auc:0.72480\n",
      "[13]\tvalidation_0-auc:0.72591\n",
      "[14]\tvalidation_0-auc:0.72593\n",
      "[15]\tvalidation_0-auc:0.72654\n",
      "[16]\tvalidation_0-auc:0.72686\n",
      "[17]\tvalidation_0-auc:0.72660\n",
      "[18]\tvalidation_0-auc:0.72781\n",
      "[19]\tvalidation_0-auc:0.72837\n",
      "[20]\tvalidation_0-auc:0.72888\n",
      "[21]\tvalidation_0-auc:0.72913\n",
      "[22]\tvalidation_0-auc:0.72954\n",
      "[23]\tvalidation_0-auc:0.73005\n",
      "[24]\tvalidation_0-auc:0.73031\n",
      "[25]\tvalidation_0-auc:0.73051\n",
      "[26]\tvalidation_0-auc:0.73049\n",
      "[27]\tvalidation_0-auc:0.73074\n",
      "[28]\tvalidation_0-auc:0.73125\n",
      "[29]\tvalidation_0-auc:0.73138\n",
      "[30]\tvalidation_0-auc:0.73188\n",
      "[31]\tvalidation_0-auc:0.73229\n",
      "[32]\tvalidation_0-auc:0.73321\n",
      "[33]\tvalidation_0-auc:0.73373\n",
      "[34]\tvalidation_0-auc:0.73400\n",
      "[35]\tvalidation_0-auc:0.73402\n",
      "[36]\tvalidation_0-auc:0.73449\n",
      "[37]\tvalidation_0-auc:0.73528\n",
      "[38]\tvalidation_0-auc:0.73616\n",
      "[39]\tvalidation_0-auc:0.73609\n",
      "[40]\tvalidation_0-auc:0.73668\n",
      "[41]\tvalidation_0-auc:0.73711\n",
      "[42]\tvalidation_0-auc:0.73733\n",
      "[43]\tvalidation_0-auc:0.73787\n",
      "[44]\tvalidation_0-auc:0.73822\n",
      "[45]\tvalidation_0-auc:0.73889\n",
      "[46]\tvalidation_0-auc:0.73897\n",
      "[47]\tvalidation_0-auc:0.73935\n",
      "[48]\tvalidation_0-auc:0.73943\n",
      "[49]\tvalidation_0-auc:0.74020\n",
      "[50]\tvalidation_0-auc:0.74055\n",
      "[51]\tvalidation_0-auc:0.74085\n",
      "[52]\tvalidation_0-auc:0.74102\n",
      "[53]\tvalidation_0-auc:0.74147\n",
      "[54]\tvalidation_0-auc:0.74198\n",
      "[55]\tvalidation_0-auc:0.74230\n",
      "[56]\tvalidation_0-auc:0.74259\n",
      "[57]\tvalidation_0-auc:0.74299\n",
      "[58]\tvalidation_0-auc:0.74317\n",
      "[59]\tvalidation_0-auc:0.74339\n",
      "[60]\tvalidation_0-auc:0.74392\n",
      "[61]\tvalidation_0-auc:0.74400\n",
      "[62]\tvalidation_0-auc:0.74421\n",
      "[63]\tvalidation_0-auc:0.74485\n",
      "[64]\tvalidation_0-auc:0.74481\n",
      "[65]\tvalidation_0-auc:0.74515\n",
      "[66]\tvalidation_0-auc:0.74551\n",
      "[67]\tvalidation_0-auc:0.74561\n",
      "[68]\tvalidation_0-auc:0.74581\n",
      "[69]\tvalidation_0-auc:0.74613\n",
      "[70]\tvalidation_0-auc:0.74645\n",
      "[71]\tvalidation_0-auc:0.74648\n",
      "[72]\tvalidation_0-auc:0.74675\n",
      "[73]\tvalidation_0-auc:0.74674\n",
      "[74]\tvalidation_0-auc:0.74677\n",
      "[75]\tvalidation_0-auc:0.74701\n",
      "[76]\tvalidation_0-auc:0.74737\n",
      "[77]\tvalidation_0-auc:0.74753\n",
      "[78]\tvalidation_0-auc:0.74757\n",
      "[79]\tvalidation_0-auc:0.74763\n",
      "[80]\tvalidation_0-auc:0.74794\n",
      "[81]\tvalidation_0-auc:0.74804\n",
      "[82]\tvalidation_0-auc:0.74828\n",
      "[83]\tvalidation_0-auc:0.74861\n",
      "[84]\tvalidation_0-auc:0.74873\n",
      "[85]\tvalidation_0-auc:0.74927\n",
      "[86]\tvalidation_0-auc:0.74942\n",
      "[87]\tvalidation_0-auc:0.74969\n",
      "[88]\tvalidation_0-auc:0.74992\n",
      "[89]\tvalidation_0-auc:0.75011\n",
      "[90]\tvalidation_0-auc:0.75018\n",
      "[91]\tvalidation_0-auc:0.75043\n",
      "[92]\tvalidation_0-auc:0.75075\n",
      "[93]\tvalidation_0-auc:0.75080\n",
      "[94]\tvalidation_0-auc:0.75100\n",
      "[95]\tvalidation_0-auc:0.75128\n",
      "[96]\tvalidation_0-auc:0.75141\n",
      "[97]\tvalidation_0-auc:0.75134\n",
      "[98]\tvalidation_0-auc:0.75148\n",
      "[99]\tvalidation_0-auc:0.75153\n",
      "[100]\tvalidation_0-auc:0.75173\n",
      "[101]\tvalidation_0-auc:0.75182\n",
      "[102]\tvalidation_0-auc:0.75170\n",
      "[103]\tvalidation_0-auc:0.75175\n",
      "[104]\tvalidation_0-auc:0.75188\n",
      "[105]\tvalidation_0-auc:0.75198\n",
      "[106]\tvalidation_0-auc:0.75218\n",
      "[107]\tvalidation_0-auc:0.75237\n",
      "[108]\tvalidation_0-auc:0.75241\n",
      "[109]\tvalidation_0-auc:0.75271\n",
      "[110]\tvalidation_0-auc:0.75297\n",
      "[111]\tvalidation_0-auc:0.75322\n",
      "[112]\tvalidation_0-auc:0.75327\n",
      "[113]\tvalidation_0-auc:0.75354\n",
      "[114]\tvalidation_0-auc:0.75354\n",
      "[115]\tvalidation_0-auc:0.75364\n",
      "[116]\tvalidation_0-auc:0.75357\n",
      "[117]\tvalidation_0-auc:0.75373\n",
      "[118]\tvalidation_0-auc:0.75371\n",
      "[119]\tvalidation_0-auc:0.75370\n",
      "[120]\tvalidation_0-auc:0.75388\n",
      "[121]\tvalidation_0-auc:0.75402\n",
      "[122]\tvalidation_0-auc:0.75427\n",
      "[123]\tvalidation_0-auc:0.75425\n",
      "[124]\tvalidation_0-auc:0.75440\n",
      "[125]\tvalidation_0-auc:0.75450\n",
      "[126]\tvalidation_0-auc:0.75446\n",
      "[127]\tvalidation_0-auc:0.75453\n",
      "[128]\tvalidation_0-auc:0.75480\n",
      "[129]\tvalidation_0-auc:0.75486\n",
      "[130]\tvalidation_0-auc:0.75485\n",
      "[131]\tvalidation_0-auc:0.75493\n",
      "[132]\tvalidation_0-auc:0.75486\n",
      "[133]\tvalidation_0-auc:0.75499\n",
      "[134]\tvalidation_0-auc:0.75500\n",
      "[135]\tvalidation_0-auc:0.75519\n",
      "[136]\tvalidation_0-auc:0.75518\n",
      "[137]\tvalidation_0-auc:0.75511\n",
      "[138]\tvalidation_0-auc:0.75506\n",
      "[139]\tvalidation_0-auc:0.75523\n",
      "[140]\tvalidation_0-auc:0.75541\n",
      "[141]\tvalidation_0-auc:0.75573\n",
      "[142]\tvalidation_0-auc:0.75572\n",
      "[143]\tvalidation_0-auc:0.75583\n",
      "[144]\tvalidation_0-auc:0.75597\n",
      "[145]\tvalidation_0-auc:0.75602\n",
      "[146]\tvalidation_0-auc:0.75615\n",
      "[147]\tvalidation_0-auc:0.75620\n",
      "[148]\tvalidation_0-auc:0.75627\n",
      "[149]\tvalidation_0-auc:0.75638\n",
      "[150]\tvalidation_0-auc:0.75635\n",
      "[151]\tvalidation_0-auc:0.75645\n",
      "[152]\tvalidation_0-auc:0.75671\n",
      "[153]\tvalidation_0-auc:0.75705\n",
      "[154]\tvalidation_0-auc:0.75706\n",
      "[155]\tvalidation_0-auc:0.75702\n",
      "[156]\tvalidation_0-auc:0.75713\n",
      "[157]\tvalidation_0-auc:0.75718\n",
      "[158]\tvalidation_0-auc:0.75732\n",
      "[159]\tvalidation_0-auc:0.75738\n",
      "[160]\tvalidation_0-auc:0.75732\n",
      "[161]\tvalidation_0-auc:0.75731\n",
      "[162]\tvalidation_0-auc:0.75735\n",
      "[163]\tvalidation_0-auc:0.75740\n",
      "[164]\tvalidation_0-auc:0.75768\n",
      "[165]\tvalidation_0-auc:0.75779\n",
      "[166]\tvalidation_0-auc:0.75786\n",
      "[167]\tvalidation_0-auc:0.75802\n",
      "[168]\tvalidation_0-auc:0.75819\n",
      "[169]\tvalidation_0-auc:0.75818\n",
      "[170]\tvalidation_0-auc:0.75828\n",
      "[171]\tvalidation_0-auc:0.75854\n",
      "[172]\tvalidation_0-auc:0.75862\n",
      "[173]\tvalidation_0-auc:0.75877\n",
      "[174]\tvalidation_0-auc:0.75876\n",
      "[175]\tvalidation_0-auc:0.75872\n",
      "[176]\tvalidation_0-auc:0.75870\n",
      "[177]\tvalidation_0-auc:0.75868\n",
      "[178]\tvalidation_0-auc:0.75869\n",
      "[179]\tvalidation_0-auc:0.75871\n",
      "[180]\tvalidation_0-auc:0.75887\n",
      "[181]\tvalidation_0-auc:0.75898\n",
      "[182]\tvalidation_0-auc:0.75907\n",
      "[183]\tvalidation_0-auc:0.75920\n",
      "[184]\tvalidation_0-auc:0.75903\n",
      "[185]\tvalidation_0-auc:0.75915\n",
      "[186]\tvalidation_0-auc:0.75918\n",
      "[187]\tvalidation_0-auc:0.75911\n",
      "[188]\tvalidation_0-auc:0.75918\n",
      "[189]\tvalidation_0-auc:0.75929\n",
      "[190]\tvalidation_0-auc:0.75935\n",
      "[191]\tvalidation_0-auc:0.75929\n",
      "[192]\tvalidation_0-auc:0.75936\n",
      "[193]\tvalidation_0-auc:0.75943\n",
      "[194]\tvalidation_0-auc:0.75940\n",
      "[195]\tvalidation_0-auc:0.75935\n",
      "[196]\tvalidation_0-auc:0.75941\n",
      "[197]\tvalidation_0-auc:0.75939\n",
      "[198]\tvalidation_0-auc:0.75944\n",
      "[199]\tvalidation_0-auc:0.75948\n",
      "[200]\tvalidation_0-auc:0.75957\n",
      "[201]\tvalidation_0-auc:0.75962\n",
      "[202]\tvalidation_0-auc:0.75963\n",
      "[203]\tvalidation_0-auc:0.75965\n",
      "[204]\tvalidation_0-auc:0.75959\n",
      "[205]\tvalidation_0-auc:0.75983\n",
      "[206]\tvalidation_0-auc:0.75992\n",
      "[207]\tvalidation_0-auc:0.75994\n",
      "[208]\tvalidation_0-auc:0.75980\n",
      "[209]\tvalidation_0-auc:0.75991\n",
      "[210]\tvalidation_0-auc:0.75995\n",
      "[211]\tvalidation_0-auc:0.75999\n",
      "[212]\tvalidation_0-auc:0.75989\n",
      "[213]\tvalidation_0-auc:0.75994\n",
      "[214]\tvalidation_0-auc:0.76001\n",
      "[215]\tvalidation_0-auc:0.76011\n",
      "[216]\tvalidation_0-auc:0.76001\n",
      "[217]\tvalidation_0-auc:0.76005\n",
      "[218]\tvalidation_0-auc:0.76013\n",
      "[219]\tvalidation_0-auc:0.76029\n",
      "[220]\tvalidation_0-auc:0.76036\n",
      "[221]\tvalidation_0-auc:0.76029\n",
      "[222]\tvalidation_0-auc:0.76030\n",
      "[223]\tvalidation_0-auc:0.76036\n",
      "[224]\tvalidation_0-auc:0.76030\n",
      "[225]\tvalidation_0-auc:0.76038\n",
      "[226]\tvalidation_0-auc:0.76048\n",
      "[227]\tvalidation_0-auc:0.76059\n",
      "[228]\tvalidation_0-auc:0.76065\n",
      "[229]\tvalidation_0-auc:0.76066\n",
      "[230]\tvalidation_0-auc:0.76081\n",
      "[231]\tvalidation_0-auc:0.76083\n",
      "[232]\tvalidation_0-auc:0.76067\n",
      "[233]\tvalidation_0-auc:0.76055\n",
      "[234]\tvalidation_0-auc:0.76061\n",
      "[235]\tvalidation_0-auc:0.76081\n",
      "[236]\tvalidation_0-auc:0.76111\n",
      "[237]\tvalidation_0-auc:0.76108\n",
      "[238]\tvalidation_0-auc:0.76096\n",
      "[239]\tvalidation_0-auc:0.76096\n",
      "[240]\tvalidation_0-auc:0.76084\n",
      "[241]\tvalidation_0-auc:0.76084\n",
      "[242]\tvalidation_0-auc:0.76074\n",
      "[243]\tvalidation_0-auc:0.76081\n",
      "[244]\tvalidation_0-auc:0.76096\n",
      "[245]\tvalidation_0-auc:0.76098\n",
      "[246]\tvalidation_0-auc:0.76100\n",
      "[247]\tvalidation_0-auc:0.76099\n",
      "[248]\tvalidation_0-auc:0.76098\n",
      "[249]\tvalidation_0-auc:0.76104\n",
      "[250]\tvalidation_0-auc:0.76094\n",
      "[251]\tvalidation_0-auc:0.76095\n",
      "[252]\tvalidation_0-auc:0.76102\n",
      "[253]\tvalidation_0-auc:0.76112\n",
      "[254]\tvalidation_0-auc:0.76122\n",
      "[255]\tvalidation_0-auc:0.76117\n",
      "[256]\tvalidation_0-auc:0.76121\n",
      "[257]\tvalidation_0-auc:0.76113\n",
      "[258]\tvalidation_0-auc:0.76102\n",
      "[259]\tvalidation_0-auc:0.76101\n",
      "[260]\tvalidation_0-auc:0.76115\n",
      "[261]\tvalidation_0-auc:0.76124\n",
      "[262]\tvalidation_0-auc:0.76117\n",
      "[263]\tvalidation_0-auc:0.76133\n",
      "[264]\tvalidation_0-auc:0.76147\n",
      "[265]\tvalidation_0-auc:0.76153\n",
      "[266]\tvalidation_0-auc:0.76151\n",
      "[267]\tvalidation_0-auc:0.76143\n",
      "[268]\tvalidation_0-auc:0.76131\n",
      "[269]\tvalidation_0-auc:0.76131\n",
      "[270]\tvalidation_0-auc:0.76143\n",
      "[271]\tvalidation_0-auc:0.76153\n",
      "[272]\tvalidation_0-auc:0.76167\n",
      "[273]\tvalidation_0-auc:0.76175\n",
      "[274]\tvalidation_0-auc:0.76185\n",
      "[275]\tvalidation_0-auc:0.76189\n",
      "[276]\tvalidation_0-auc:0.76202\n",
      "[277]\tvalidation_0-auc:0.76191\n",
      "[278]\tvalidation_0-auc:0.76189\n",
      "[279]\tvalidation_0-auc:0.76184\n",
      "[280]\tvalidation_0-auc:0.76181\n",
      "[281]\tvalidation_0-auc:0.76179\n",
      "[282]\tvalidation_0-auc:0.76178\n",
      "[283]\tvalidation_0-auc:0.76195\n",
      "[284]\tvalidation_0-auc:0.76199\n",
      "[285]\tvalidation_0-auc:0.76190\n",
      "[286]\tvalidation_0-auc:0.76190\n",
      "[287]\tvalidation_0-auc:0.76167\n",
      "[288]\tvalidation_0-auc:0.76173\n",
      "[289]\tvalidation_0-auc:0.76181\n",
      "[290]\tvalidation_0-auc:0.76180\n",
      "[291]\tvalidation_0-auc:0.76176\n",
      "[292]\tvalidation_0-auc:0.76185\n",
      "[293]\tvalidation_0-auc:0.76186\n",
      "[294]\tvalidation_0-auc:0.76187\n",
      "[295]\tvalidation_0-auc:0.76193\n",
      "[296]\tvalidation_0-auc:0.76197\n",
      "[297]\tvalidation_0-auc:0.76196\n",
      "[298]\tvalidation_0-auc:0.76207\n",
      "[299]\tvalidation_0-auc:0.76214\n",
      "[300]\tvalidation_0-auc:0.76206\n",
      "[301]\tvalidation_0-auc:0.76211\n",
      "[302]\tvalidation_0-auc:0.76229\n",
      "[303]\tvalidation_0-auc:0.76225\n",
      "[304]\tvalidation_0-auc:0.76228\n",
      "[305]\tvalidation_0-auc:0.76224\n",
      "[306]\tvalidation_0-auc:0.76231\n",
      "[307]\tvalidation_0-auc:0.76239\n",
      "[308]\tvalidation_0-auc:0.76247\n",
      "[309]\tvalidation_0-auc:0.76243\n",
      "[310]\tvalidation_0-auc:0.76251\n",
      "[311]\tvalidation_0-auc:0.76258\n",
      "[312]\tvalidation_0-auc:0.76273\n",
      "[313]\tvalidation_0-auc:0.76268\n",
      "[314]\tvalidation_0-auc:0.76281\n",
      "[315]\tvalidation_0-auc:0.76286\n",
      "[316]\tvalidation_0-auc:0.76288\n",
      "[317]\tvalidation_0-auc:0.76291\n",
      "[318]\tvalidation_0-auc:0.76292\n",
      "[319]\tvalidation_0-auc:0.76292\n",
      "[320]\tvalidation_0-auc:0.76281\n",
      "[321]\tvalidation_0-auc:0.76284\n",
      "[322]\tvalidation_0-auc:0.76285\n",
      "[323]\tvalidation_0-auc:0.76300\n",
      "[324]\tvalidation_0-auc:0.76304\n",
      "[325]\tvalidation_0-auc:0.76304\n",
      "[326]\tvalidation_0-auc:0.76319\n",
      "[327]\tvalidation_0-auc:0.76318\n",
      "[328]\tvalidation_0-auc:0.76318\n",
      "[329]\tvalidation_0-auc:0.76314\n",
      "[330]\tvalidation_0-auc:0.76314\n",
      "[331]\tvalidation_0-auc:0.76325\n",
      "[332]\tvalidation_0-auc:0.76327\n",
      "[333]\tvalidation_0-auc:0.76343\n",
      "[334]\tvalidation_0-auc:0.76341\n",
      "[335]\tvalidation_0-auc:0.76345\n",
      "[336]\tvalidation_0-auc:0.76343\n",
      "[337]\tvalidation_0-auc:0.76358\n",
      "[338]\tvalidation_0-auc:0.76358\n",
      "[339]\tvalidation_0-auc:0.76360\n",
      "[340]\tvalidation_0-auc:0.76363\n",
      "[341]\tvalidation_0-auc:0.76366\n",
      "[342]\tvalidation_0-auc:0.76378\n",
      "[343]\tvalidation_0-auc:0.76380\n",
      "[344]\tvalidation_0-auc:0.76380\n",
      "[345]\tvalidation_0-auc:0.76400\n",
      "[346]\tvalidation_0-auc:0.76390\n",
      "[347]\tvalidation_0-auc:0.76389\n",
      "[348]\tvalidation_0-auc:0.76395\n",
      "[349]\tvalidation_0-auc:0.76405\n",
      "[350]\tvalidation_0-auc:0.76415\n",
      "[351]\tvalidation_0-auc:0.76411\n",
      "[352]\tvalidation_0-auc:0.76413\n",
      "[353]\tvalidation_0-auc:0.76412\n",
      "[354]\tvalidation_0-auc:0.76393\n",
      "[355]\tvalidation_0-auc:0.76397\n",
      "[356]\tvalidation_0-auc:0.76398\n",
      "[357]\tvalidation_0-auc:0.76396\n",
      "[358]\tvalidation_0-auc:0.76393\n",
      "[359]\tvalidation_0-auc:0.76389\n",
      "[360]\tvalidation_0-auc:0.76390\n",
      "[361]\tvalidation_0-auc:0.76393\n",
      "[362]\tvalidation_0-auc:0.76390\n",
      "[363]\tvalidation_0-auc:0.76387\n",
      "[364]\tvalidation_0-auc:0.76389\n",
      "[365]\tvalidation_0-auc:0.76392\n",
      "[366]\tvalidation_0-auc:0.76399\n",
      "[367]\tvalidation_0-auc:0.76401\n",
      "[368]\tvalidation_0-auc:0.76401\n",
      "[369]\tvalidation_0-auc:0.76406\n",
      "[370]\tvalidation_0-auc:0.76410\n",
      "[371]\tvalidation_0-auc:0.76408\n",
      "[372]\tvalidation_0-auc:0.76411\n",
      "[373]\tvalidation_0-auc:0.76413\n",
      "[374]\tvalidation_0-auc:0.76410\n",
      "[375]\tvalidation_0-auc:0.76423\n",
      "[376]\tvalidation_0-auc:0.76427\n",
      "[377]\tvalidation_0-auc:0.76442\n",
      "[378]\tvalidation_0-auc:0.76439\n",
      "[379]\tvalidation_0-auc:0.76448\n",
      "[380]\tvalidation_0-auc:0.76440\n",
      "[381]\tvalidation_0-auc:0.76447\n",
      "[382]\tvalidation_0-auc:0.76441\n",
      "[383]\tvalidation_0-auc:0.76438\n",
      "[384]\tvalidation_0-auc:0.76435\n",
      "[385]\tvalidation_0-auc:0.76444\n",
      "[386]\tvalidation_0-auc:0.76452\n",
      "[387]\tvalidation_0-auc:0.76454\n",
      "[388]\tvalidation_0-auc:0.76448\n",
      "[389]\tvalidation_0-auc:0.76450\n",
      "[390]\tvalidation_0-auc:0.76449\n",
      "[391]\tvalidation_0-auc:0.76463\n",
      "[392]\tvalidation_0-auc:0.76461\n",
      "[393]\tvalidation_0-auc:0.76473\n",
      "[394]\tvalidation_0-auc:0.76479\n",
      "[395]\tvalidation_0-auc:0.76491\n",
      "[396]\tvalidation_0-auc:0.76498\n",
      "[397]\tvalidation_0-auc:0.76496\n",
      "[398]\tvalidation_0-auc:0.76503\n",
      "[399]\tvalidation_0-auc:0.76509\n",
      "[400]\tvalidation_0-auc:0.76526\n",
      "[401]\tvalidation_0-auc:0.76527\n",
      "[402]\tvalidation_0-auc:0.76532\n",
      "[403]\tvalidation_0-auc:0.76543\n",
      "[404]\tvalidation_0-auc:0.76548\n",
      "[405]\tvalidation_0-auc:0.76557\n",
      "[406]\tvalidation_0-auc:0.76557\n",
      "[407]\tvalidation_0-auc:0.76548\n",
      "[408]\tvalidation_0-auc:0.76556\n",
      "[409]\tvalidation_0-auc:0.76556\n",
      "[410]\tvalidation_0-auc:0.76559\n",
      "[411]\tvalidation_0-auc:0.76559\n",
      "[412]\tvalidation_0-auc:0.76557\n",
      "[413]\tvalidation_0-auc:0.76556\n",
      "[414]\tvalidation_0-auc:0.76548\n",
      "[415]\tvalidation_0-auc:0.76548\n",
      "[416]\tvalidation_0-auc:0.76558\n",
      "[417]\tvalidation_0-auc:0.76564\n",
      "[418]\tvalidation_0-auc:0.76565\n",
      "[419]\tvalidation_0-auc:0.76559\n",
      "[420]\tvalidation_0-auc:0.76564\n",
      "[421]\tvalidation_0-auc:0.76577\n",
      "[422]\tvalidation_0-auc:0.76592\n",
      "[423]\tvalidation_0-auc:0.76591\n",
      "[424]\tvalidation_0-auc:0.76600\n",
      "[425]\tvalidation_0-auc:0.76610\n",
      "[426]\tvalidation_0-auc:0.76610\n",
      "[427]\tvalidation_0-auc:0.76610\n",
      "[428]\tvalidation_0-auc:0.76611\n",
      "[429]\tvalidation_0-auc:0.76608\n",
      "[430]\tvalidation_0-auc:0.76611\n",
      "[431]\tvalidation_0-auc:0.76612\n",
      "[432]\tvalidation_0-auc:0.76621\n",
      "[433]\tvalidation_0-auc:0.76620\n",
      "[434]\tvalidation_0-auc:0.76627\n",
      "[435]\tvalidation_0-auc:0.76628\n",
      "[436]\tvalidation_0-auc:0.76634\n",
      "[437]\tvalidation_0-auc:0.76645\n",
      "[438]\tvalidation_0-auc:0.76646\n",
      "[439]\tvalidation_0-auc:0.76655\n",
      "[440]\tvalidation_0-auc:0.76661\n",
      "[441]\tvalidation_0-auc:0.76672\n",
      "[442]\tvalidation_0-auc:0.76674\n",
      "[443]\tvalidation_0-auc:0.76682\n",
      "[444]\tvalidation_0-auc:0.76681\n",
      "[445]\tvalidation_0-auc:0.76678\n",
      "[446]\tvalidation_0-auc:0.76674\n",
      "[447]\tvalidation_0-auc:0.76688\n",
      "[448]\tvalidation_0-auc:0.76683\n",
      "[449]\tvalidation_0-auc:0.76685\n",
      "[450]\tvalidation_0-auc:0.76692\n",
      "[451]\tvalidation_0-auc:0.76703\n",
      "[452]\tvalidation_0-auc:0.76699\n",
      "[453]\tvalidation_0-auc:0.76704\n",
      "[454]\tvalidation_0-auc:0.76712\n",
      "[455]\tvalidation_0-auc:0.76722\n",
      "[456]\tvalidation_0-auc:0.76722\n",
      "[457]\tvalidation_0-auc:0.76718\n",
      "[458]\tvalidation_0-auc:0.76718\n",
      "[459]\tvalidation_0-auc:0.76711\n",
      "[460]\tvalidation_0-auc:0.76709\n",
      "[461]\tvalidation_0-auc:0.76717\n",
      "[462]\tvalidation_0-auc:0.76716\n",
      "[463]\tvalidation_0-auc:0.76718\n",
      "[464]\tvalidation_0-auc:0.76715\n",
      "[465]\tvalidation_0-auc:0.76712\n",
      "[466]\tvalidation_0-auc:0.76710\n",
      "[467]\tvalidation_0-auc:0.76714\n",
      "[468]\tvalidation_0-auc:0.76724\n",
      "[469]\tvalidation_0-auc:0.76719\n",
      "[470]\tvalidation_0-auc:0.76707\n",
      "[471]\tvalidation_0-auc:0.76705\n",
      "[472]\tvalidation_0-auc:0.76696\n",
      "[473]\tvalidation_0-auc:0.76696\n",
      "[474]\tvalidation_0-auc:0.76698\n",
      "[475]\tvalidation_0-auc:0.76702\n",
      "[476]\tvalidation_0-auc:0.76711\n",
      "[477]\tvalidation_0-auc:0.76708\n",
      "[478]\tvalidation_0-auc:0.76715\n",
      "[479]\tvalidation_0-auc:0.76719\n",
      "[480]\tvalidation_0-auc:0.76730\n",
      "[481]\tvalidation_0-auc:0.76725\n",
      "[482]\tvalidation_0-auc:0.76720\n",
      "[483]\tvalidation_0-auc:0.76713\n",
      "[484]\tvalidation_0-auc:0.76707\n",
      "[485]\tvalidation_0-auc:0.76707\n",
      "[486]\tvalidation_0-auc:0.76697\n",
      "[487]\tvalidation_0-auc:0.76702\n",
      "[488]\tvalidation_0-auc:0.76706\n",
      "[489]\tvalidation_0-auc:0.76710\n",
      "[490]\tvalidation_0-auc:0.76710\n",
      "[491]\tvalidation_0-auc:0.76717\n",
      "[492]\tvalidation_0-auc:0.76713\n",
      "[493]\tvalidation_0-auc:0.76713\n",
      "[494]\tvalidation_0-auc:0.76721\n",
      "[495]\tvalidation_0-auc:0.76725\n",
      "[496]\tvalidation_0-auc:0.76717\n",
      "[497]\tvalidation_0-auc:0.76720\n",
      "[498]\tvalidation_0-auc:0.76722\n",
      "[499]\tvalidation_0-auc:0.76715\n",
      "\n",
      "üìä Model Performance:\n",
      "  AUC-ROC: 0.7672\n",
      "  AUC-PR: 0.2505\n",
      "\n",
      "üìä Standard Threshold (0.5):\n",
      "  Recall: 57.95%\n",
      "  Precision: 21.08%\n",
      "  F1-Score: 0.3091\n",
      "  Defaults Missed: 828\n",
      "  Total Cost: $265,092,000\n",
      "\n",
      "üìä Optimal Threshold (0.003):\n",
      "  Recall: 100.00%\n",
      "  Precision: 8.08%\n",
      "  F1-Score: 0.1495\n",
      "  Defaults Missed: 0\n",
      "  Total Cost: $22,400,000\n",
      "  Net Savings: $597,835,000\n",
      "  ROI: 2668.9%\n",
      "\n",
      "üîç Performing SHAP analysis for XGBoost...\n",
      "  ‚ö†Ô∏è SHAP TreeExplainer failed, using model's built-in feature importance\n",
      "  ‚úì Feature importance analysis complete (using built-in method)\n",
      "  Top 5 features: Score_Source_3_Available, Score_Source_3, Score_Source_2_Available, Score_Source_2, Client_Education\n",
      "\n",
      "==================================================\n",
      "Training LightGBM\n",
      "==================================================\n",
      "\n",
      "üìä Model Performance:\n",
      "  AUC-ROC: 0.7653\n",
      "  AUC-PR: 0.2433\n",
      "\n",
      "üìä Standard Threshold (0.5):\n",
      "  Recall: 61.91%\n",
      "  Precision: 19.15%\n",
      "  F1-Score: 0.2925\n",
      "  Defaults Missed: 750\n",
      "  Total Cost: $241,397,000\n",
      "\n",
      "üìä Optimal Threshold (0.003):\n",
      "  Recall: 100.00%\n",
      "  Precision: 8.08%\n",
      "  F1-Score: 0.1495\n",
      "  Defaults Missed: 0\n",
      "  Total Cost: $22,401,000\n",
      "  Net Savings: $597,834,000\n",
      "  ROI: 2668.8%\n",
      "\n",
      "üîç Performing SHAP analysis for LightGBM...\n",
      "  ‚úì SHAP analysis complete for LightGBM\n",
      "  Top 5 features: Score_Source_3, Score_Source_2, Score_Source_1, Credit_Annuity_Ratio, Client_Education\n",
      "\n",
      "====================================================================================================\n",
      "üéØ CALIBRATING MODELS\n",
      "====================================================================================================\n",
      "\n",
      "Calibrating Logistic Regression...\n",
      "  Original AUC: 0.7330\n",
      "  Calibrated AUC: 0.7329\n",
      "  Improvement: -0.0002\n",
      "\n",
      "Calibrating XGBoost...\n",
      "  Original AUC: 0.7672\n",
      "  Calibrated AUC: 0.7713\n",
      "  Improvement: +0.0041\n",
      "\n",
      "Calibrating LightGBM...\n",
      "  Original AUC: 0.7653\n",
      "  Calibrated AUC: 0.7665\n",
      "  Improvement: +0.0012\n",
      "\n",
      "üìà Generating visualizations...\n",
      "\n",
      "üíæ Saving models and results...\n",
      "  ‚úì Saved Logistic Regression ‚Üí artifacts/models/logistic_regression.pkl\n",
      "  ‚úì Saved XGBoost ‚Üí artifacts/models/xgboost.pkl\n",
      "  ‚úì Saved LightGBM ‚Üí artifacts/models/lightgbm.pkl\n",
      "\n",
      "====================================================================================================\n",
      "üìä FINAL MODEL COMPARISON REPORT\n",
      "====================================================================================================\n",
      "\n",
      "üèÜ Model Rankings by Net Savings:\n",
      "\n",
      "2. XGBoost\n",
      "   Net Savings: $597,835,000\n",
      "   ROI: 2668.9%\n",
      "   AUC-ROC: 0.7672 (CV: 0.7674 ¬± 0.0039)\n",
      "   Optimal Threshold: 0.003\n",
      "   Cost Reduction: $242,692,000\n",
      "\n",
      "3. LightGBM\n",
      "   Net Savings: $597,834,000\n",
      "   ROI: 2668.8%\n",
      "   AUC-ROC: 0.7653 (CV: 0.7643 ¬± 0.0054)\n",
      "   Optimal Threshold: 0.003\n",
      "   Cost Reduction: $218,996,000\n",
      "\n",
      "1. Logistic Regression\n",
      "   Net Savings: $597,833,000\n",
      "   ROI: 2668.7%\n",
      "   AUC-ROC: 0.7330 (CV: 0.7361 ¬± 0.0053)\n",
      "   Optimal Threshold: 0.000\n",
      "   Cost Reduction: $187,361,000\n",
      "\n",
      "üéØ RECOMMENDED MODEL: XGBoost\n",
      "   Expected Annual Savings: $7,174,020,000\n",
      "   Defaults Caught: 100.0%\n",
      "   False Alarm Rate: 91.9%\n",
      "\n",
      "‚úÖ Enhanced training pipeline completed successfully!\n",
      "üìÅ All artifacts saved in 'artifacts/' directory\n",
      "üìä Check 'artifacts/shap/' for feature importance visualizations\n",
      "üìà Check 'artifacts/plots/' for performance visualizations\n",
      "üìã Check 'artifacts/reports/' for detailed reports\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Enhanced Loan Default Prediction Training Pipeline\n",
    "=================================================\n",
    "This pipeline includes:\n",
    "- K-Fold Cross Validation\n",
    "- SHAP feature importance analysis\n",
    "- Threshold optimization\n",
    "- Model calibration\n",
    "- Business metrics\n",
    "- Early stopping for boosting models\n",
    "\n",
    "Author: Data Science Team\n",
    "Date: November 2025\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, precision_recall_curve, auc,\n",
    "    classification_report, confusion_matrix,\n",
    "    roc_curve, f1_score,\n",
    "    make_scorer\n",
    ")\n",
    "\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold, cross_val_score,\n",
    "    cross_validate\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"üè¶ ENHANCED LOAN DEFAULT PREDICTION - MODEL TRAINING PIPELINE\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# =====================================================================\n",
    "# CONFIGURATION\n",
    "# =====================================================================\n",
    "RANDOM_SEED = 42\n",
    "N_FOLDS = 5\n",
    "DEFAULT_COST = 315000  # Cost of missed default\n",
    "INVESTIGATION_COST = 1000  # Cost to investigate flagged loan\n",
    "EARLY_STOPPING_ROUNDS = 50\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(\"artifacts/models\", exist_ok=True)\n",
    "os.makedirs(\"artifacts/reports\", exist_ok=True)\n",
    "os.makedirs(\"artifacts/plots\", exist_ok=True)\n",
    "os.makedirs(\"artifacts/shap\", exist_ok=True)\n",
    "\n",
    "# =====================================================================\n",
    "# STEP 1: LOAD ENCODED DATA\n",
    "# =====================================================================\n",
    "print(\"\\nüì• Loading encoded data...\")\n",
    "\n",
    "X_train = pd.read_csv('processed_data/X_train_encoded.csv')\n",
    "X_test = pd.read_csv('processed_data/X_test_encoded.csv')\n",
    "y_train = pd.read_csv('processed_data/y_train.csv').values.ravel()\n",
    "y_test = pd.read_csv('processed_data/y_test.csv').values.ravel()\n",
    "\n",
    "print(f\"‚úì Training data shape: {X_train.shape}\")\n",
    "print(f\"‚úì Testing  data shape: {X_test.shape}\")\n",
    "print(f\"‚úì Target distribution:\")\n",
    "print(f\"  - No Default (0): {(y_train==0).sum():,} ({(y_train==0).sum()/len(y_train):.1%})\")\n",
    "print(f\"  - Default (1): {(y_train==1).sum():,} ({(y_train==1).sum()/len(y_train):.1%})\")\n",
    "print(f\"‚úì Imbalance ratio: {(y_train==0).sum() / (y_train==1).sum():.1f}:1\")\n",
    "\n",
    "# =====================================================================\n",
    "# STEP 2: MODEL CONFIGURATION\n",
    "# =====================================================================\n",
    "# Calculate actual scale_pos_weight from data\n",
    "calculated_scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"\\n‚öñÔ∏è Calculated scale_pos_weight: {calculated_scale_pos_weight:.2f}\")\n",
    "\n",
    "# You can adjust this based on business requirements\n",
    "# Higher values = fewer false negatives (missed defaults)\n",
    "# Lower values = fewer false positives (unnecessary investigations)\n",
    "SCALE_POS_WEIGHT = calculated_scale_pos_weight  # Use actual imbalance ratio\n",
    "\n",
    "print(f\"‚öñÔ∏è Using scale_pos_weight: {SCALE_POS_WEIGHT:.2f}\")\n",
    "\n",
    "models_config = {\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        class_weight='balanced',\n",
    "        max_iter=1000,\n",
    "        random_state=RANDOM_SEED,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        scale_pos_weight=SCALE_POS_WEIGHT,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        n_estimators=500,\n",
    "        min_child_weight=1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        gamma=0,\n",
    "        random_state=RANDOM_SEED,\n",
    "        eval_metric='auc',\n",
    "        early_stopping_rounds=None,\n",
    "        n_jobs=-1,\n",
    "        verbosity=0\n",
    "    ),\n",
    "    \"LightGBM\": LGBMClassifier(\n",
    "        scale_pos_weight=SCALE_POS_WEIGHT,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        n_estimators=500,\n",
    "        num_leaves=31,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=RANDOM_SEED,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1,\n",
    "        metric='auc',\n",
    "        early_stopping_rounds=None\n",
    "    )\n",
    "}\n",
    "\n",
    "# =====================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# =====================================================================\n",
    "\n",
    "def find_optimal_threshold(y_true, y_scores, metric='f1'):\n",
    "    \"\"\"\n",
    "    Find optimal threshold for classification.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_true : array-like\n",
    "        True labels\n",
    "    y_scores : array-like\n",
    "        Predicted probabilities\n",
    "    metric : str\n",
    "        Metric to optimize ('f1', 'business', 'balanced')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    optimal_threshold : float\n",
    "        Best threshold value\n",
    "    best_score : float\n",
    "        Best score achieved\n",
    "    \"\"\"\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_scores)\n",
    "    \n",
    "    if metric == 'f1':\n",
    "        # Optimize F1 score\n",
    "        f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "        best_idx = np.argmax(f1_scores[:-1])  # Exclude last point\n",
    "        return thresholds[best_idx], f1_scores[best_idx]\n",
    "    \n",
    "    elif metric == 'business':\n",
    "        # Optimize based on business costs\n",
    "        best_cost = float('inf')\n",
    "        best_threshold = 0.5\n",
    "        \n",
    "        for threshold in thresholds:\n",
    "            y_pred = (y_scores >= threshold).astype(int)\n",
    "            cm = confusion_matrix(y_true, y_pred)\n",
    "            \n",
    "            false_negatives = cm[1,0] if cm.shape[0] > 1 else 0\n",
    "            false_positives = cm[0,1] if cm.shape[0] > 1 else 0\n",
    "            \n",
    "            total_cost = (false_negatives * DEFAULT_COST) + (false_positives * INVESTIGATION_COST)\n",
    "            \n",
    "            if total_cost < best_cost:\n",
    "                best_cost = total_cost\n",
    "                best_threshold = threshold\n",
    "        \n",
    "        return best_threshold, -best_cost  # Return negative cost as score\n",
    "    \n",
    "    else:  # balanced\n",
    "        # Balance between precision and recall\n",
    "        f_scores = (1 + 0.5**2) * (precision * recall) / (0.5**2 * precision + recall + 1e-8)\n",
    "        best_idx = np.argmax(f_scores[:-1])\n",
    "        return thresholds[best_idx], f_scores[best_idx]\n",
    "\n",
    "\n",
    "def calculate_business_metrics(y_true, y_pred, y_scores=None):\n",
    "    \"\"\"Calculate business-focused metrics.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    if cm.shape[0] > 1:\n",
    "        true_negatives = cm[0,0]\n",
    "        false_positives = cm[0,1]\n",
    "        false_negatives = cm[1,0]\n",
    "        true_positives = cm[1,1]\n",
    "    else:\n",
    "        # Handle edge case where only one class is predicted\n",
    "        true_negatives = cm[0,0] if y_pred[0] == 0 else 0\n",
    "        false_positives = false_negatives = true_positives = 0\n",
    "    \n",
    "    # Calculate costs\n",
    "    default_loss = false_negatives * DEFAULT_COST\n",
    "    investigation_cost = false_positives * INVESTIGATION_COST\n",
    "    total_cost = default_loss + investigation_cost\n",
    "    \n",
    "    # Calculate savings (defaults prevented)\n",
    "    defaults_prevented = true_positives\n",
    "    potential_savings = defaults_prevented * DEFAULT_COST\n",
    "    net_savings = potential_savings - investigation_cost\n",
    "    \n",
    "    metrics = {\n",
    "        'defaults_missed': false_negatives,\n",
    "        'false_alarms': false_positives,\n",
    "        'defaults_caught': true_positives,\n",
    "        'default_loss': default_loss,\n",
    "        'investigation_cost': investigation_cost,\n",
    "        'total_cost': total_cost,\n",
    "        'potential_savings': potential_savings,\n",
    "        'net_savings': net_savings,\n",
    "        'roi': (net_savings / investigation_cost * 100) if investigation_cost > 0 else 0\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def plot_calibration_curve(y_true, probas_dict, save_path):\n",
    "    \"\"\"Plot calibration curves for multiple models.\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    for name, y_prob in probas_dict.items():\n",
    "        fraction_true, fraction_pred = calibration_curve(y_true, y_prob, n_bins=10)\n",
    "        plt.plot(fraction_pred, fraction_true, marker='o', linewidth=2, label=name)\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfectly calibrated')\n",
    "    plt.xlabel('Mean Predicted Probability', fontsize=12)\n",
    "    plt.ylabel('Fraction of Positives', fontsize=12)\n",
    "    plt.title('Calibration Curves - Model Reliability', fontsize=14)\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_roc_curves(y_true, probas_dict, save_path):\n",
    "    \"\"\"Plot ROC curves for multiple models.\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    for name, y_prob in probas_dict.items():\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "        auc_score = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, linewidth=2, label=f'{name} (AUC = {auc_score:.3f})')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random')\n",
    "    plt.xlabel('False Positive Rate', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate', fontsize=12)\n",
    "    plt.title('ROC Curves - Model Performance', fontsize=14)\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def perform_shap_analysis(model, X_train, X_test, model_name, sample_size=1000):\n",
    "    \"\"\"\n",
    "    Perform SHAP analysis for feature importance.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : fitted model\n",
    "        The trained model\n",
    "    X_train : pd.DataFrame\n",
    "        Training data\n",
    "    X_test : pd.DataFrame\n",
    "        Test data\n",
    "    model_name : str\n",
    "        Name of the model\n",
    "    sample_size : int\n",
    "        Number of samples to use for SHAP (for speed)\n",
    "    \"\"\"\n",
    "    print(f\"\\nüîç Performing SHAP analysis for {model_name}...\")\n",
    "    \n",
    "    try:\n",
    "        # Sample data for faster computation\n",
    "        if X_train.shape[0] > sample_size:\n",
    "            sample_idx = np.random.choice(X_train.index, sample_size, replace=False)\n",
    "            X_sample = X_train.loc[sample_idx]\n",
    "            X_test_sample = X_test.iloc[:min(sample_size, len(X_test))]\n",
    "        else:\n",
    "            X_sample = X_train\n",
    "            X_test_sample = X_test\n",
    "        \n",
    "        # Create SHAP explainer\n",
    "        if model_name == \"Logistic Regression\":\n",
    "            explainer = shap.LinearExplainer(model, X_sample)\n",
    "            shap_values = explainer.shap_values(X_test_sample)\n",
    "        else:\n",
    "            # For tree-based models - use different approaches for XGBoost vs LightGBM\n",
    "            if model_name == \"XGBoost\":\n",
    "                # For XGBoost, use the model's internal feature importance as fallback\n",
    "                try:\n",
    "                    explainer = shap.TreeExplainer(model)\n",
    "                    shap_values = explainer.shap_values(X_test_sample)\n",
    "                    if isinstance(shap_values, list):\n",
    "                        shap_values = shap_values[1]\n",
    "                except:\n",
    "                    print(f\"  ‚ö†Ô∏è SHAP TreeExplainer failed, using model's built-in feature importance\")\n",
    "                    # Use XGBoost's built-in feature importance\n",
    "                    feature_importance = pd.DataFrame({\n",
    "                        'feature': X_test.columns,\n",
    "                        'shap_importance': model.feature_importances_\n",
    "                    }).sort_values('shap_importance', ascending=False)\n",
    "                    \n",
    "                    # Save the feature importance\n",
    "                    feature_importance.to_csv(\n",
    "                        f'artifacts/reports/{model_name.lower().replace(\" \", \"_\")}_feature_importance.csv', \n",
    "                        index=False\n",
    "                    )\n",
    "                    \n",
    "                    # Create a simple bar plot\n",
    "                    plt.figure(figsize=(10, 8))\n",
    "                    top_features = feature_importance.head(20)\n",
    "                    plt.barh(range(len(top_features)), top_features['shap_importance'])\n",
    "                    plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "                    plt.xlabel('Feature Importance', fontsize=12)\n",
    "                    plt.title(f'Top 20 Features - {model_name}', fontsize=14)\n",
    "                    plt.gca().invert_yaxis()\n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig(f'artifacts/shap/{model_name.lower().replace(\" \", \"_\")}_importance.png', \n",
    "                                dpi=300, bbox_inches='tight')\n",
    "                    plt.close()\n",
    "                    \n",
    "                    print(f\"  ‚úì Feature importance analysis complete (using built-in method)\")\n",
    "                    print(f\"  Top 5 features: {', '.join(feature_importance.head(5)['feature'].tolist())}\")\n",
    "                    return feature_importance\n",
    "            else:\n",
    "                # For LightGBM\n",
    "                explainer = shap.TreeExplainer(model)\n",
    "                shap_values = explainer.shap_values(X_test_sample)\n",
    "                if isinstance(shap_values, list):\n",
    "                    shap_values = shap_values[1]\n",
    "        \n",
    "        # Save SHAP summary plot\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        shap.summary_plot(shap_values, X_test_sample, show=False, max_display=20)\n",
    "        plt.title(f'SHAP Summary Plot - {model_name}', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'artifacts/shap/{model_name.lower().replace(\" \", \"_\")}_summary.png', \n",
    "                    dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # Calculate and save feature importance\n",
    "        shap_importance = np.abs(shap_values).mean(axis=0)\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': X_test.columns,\n",
    "            'shap_importance': shap_importance\n",
    "        }).sort_values('shap_importance', ascending=False)\n",
    "        \n",
    "        # Save top 20 features plot\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        top_features = feature_importance.head(20)\n",
    "        plt.barh(range(len(top_features)), top_features['shap_importance'])\n",
    "        plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "        plt.xlabel('Mean |SHAP value|', fontsize=12)\n",
    "        plt.title(f'Top 20 Features - {model_name}', fontsize=14)\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'artifacts/shap/{model_name.lower().replace(\" \", \"_\")}_importance.png', \n",
    "                    dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # Save feature importance to CSV\n",
    "        feature_importance.to_csv(\n",
    "            f'artifacts/reports/{model_name.lower().replace(\" \", \"_\")}_feature_importance.csv', \n",
    "            index=False\n",
    "        )\n",
    "        \n",
    "        print(f\"  ‚úì SHAP analysis complete for {model_name}\")\n",
    "        print(f\"  Top 5 features: {', '.join(feature_importance.head(5)['feature'].tolist())}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è SHAP analysis failed for {model_name}: {str(e)}\")\n",
    "        print(f\"  Using model's built-in feature importance instead...\")\n",
    "        \n",
    "        # Fallback to built-in feature importance for tree models\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            feature_importance = pd.DataFrame({\n",
    "                'feature': X_test.columns,\n",
    "                'importance': model.feature_importances_\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            \n",
    "            # Save the feature importance\n",
    "            feature_importance.to_csv(\n",
    "                f'artifacts/reports/{model_name.lower().replace(\" \", \"_\")}_feature_importance.csv', \n",
    "                index=False\n",
    "            )\n",
    "            \n",
    "            # Create a simple bar plot\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            top_features = feature_importance.head(20)\n",
    "            plt.barh(range(len(top_features)), top_features['importance'])\n",
    "            plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "            plt.xlabel('Feature Importance', fontsize=12)\n",
    "            plt.title(f'Top 20 Features - {model_name}', fontsize=14)\n",
    "            plt.gca().invert_yaxis()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'artifacts/shap/{model_name.lower().replace(\" \", \"_\")}_importance.png', \n",
    "                        dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "            print(f\"  ‚úì Feature importance saved using built-in method\")\n",
    "            return feature_importance\n",
    "        else:\n",
    "            print(f\"  ‚úó No feature importance available for {model_name}\")\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    return feature_importance\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# STEP 3: K-FOLD CROSS VALIDATION\n",
    "# =====================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üìä PERFORMING K-FOLD CROSS VALIDATION\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Define stratified k-fold\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "# Define scoring metrics\n",
    "scoring = {\n",
    "    'roc_auc': 'roc_auc',\n",
    "    'precision': make_scorer(lambda y_true, y_pred: \n",
    "                           classification_report(y_true, y_pred, output_dict=True)['1']['precision']),\n",
    "    'recall': make_scorer(lambda y_true, y_pred: \n",
    "                        classification_report(y_true, y_pred, output_dict=True)['1']['recall']),\n",
    "    'f1': make_scorer(f1_score, pos_label=1)\n",
    "}\n",
    "\n",
    "cv_results = {}\n",
    "\n",
    "for name, model in models_config.items():\n",
    "    print(f\"\\nüîÑ Cross-validating {name}...\")\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_validate(\n",
    "        model, X_train, y_train, \n",
    "        cv=skf, \n",
    "        scoring=scoring,\n",
    "        n_jobs=-1,\n",
    "        return_train_score=False\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    cv_results[name] = {\n",
    "        'auc_mean': cv_scores['test_roc_auc'].mean(),\n",
    "        'auc_std': cv_scores['test_roc_auc'].std(),\n",
    "        'precision_mean': cv_scores['test_precision'].mean(),\n",
    "        'precision_std': cv_scores['test_precision'].std(),\n",
    "        'recall_mean': cv_scores['test_recall'].mean(),\n",
    "        'recall_std': cv_scores['test_recall'].std(),\n",
    "        'f1_mean': cv_scores['test_f1'].mean(),\n",
    "        'f1_std': cv_scores['test_f1'].std()\n",
    "    }\n",
    "    \n",
    "    print(f\"  ‚úì AUC-ROC: {cv_results[name]['auc_mean']:.4f} (+/- {cv_results[name]['auc_std']:.4f})\")\n",
    "    print(f\"  ‚úì Recall: {cv_results[name]['recall_mean']:.4f} (+/- {cv_results[name]['recall_std']:.4f})\")\n",
    "    print(f\"  ‚úì F1-Score: {cv_results[name]['f1_mean']:.4f} (+/- {cv_results[name]['f1_std']:.4f})\")\n",
    "\n",
    "# Save CV results\n",
    "cv_df = pd.DataFrame(cv_results).T\n",
    "cv_df.to_csv('artifacts/reports/cross_validation_results.csv')\n",
    "\n",
    "# =====================================================================\n",
    "# STEP 4: FINAL MODEL TRAINING AND EVALUATION\n",
    "# =====================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üöÄ TRAINING FINAL MODELS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "results = []\n",
    "trained_models = {}\n",
    "probas_dict = {}\n",
    "\n",
    "for name, model in models_config.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training {name}\")\n",
    "    print('='*50)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Handle early stopping for boosting models\n",
    "    if name in ['XGBoost', 'LightGBM']:\n",
    "        eval_set = [(X_test, y_test)]\n",
    "        model.fit(X_train, y_train, eval_set=eval_set) #, verbose=False\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    probas_dict[name] = y_pred_proba\n",
    "    \n",
    "    # Find optimal thresholds\n",
    "    threshold_f1, best_f1 = find_optimal_threshold(y_test, y_pred_proba, metric='f1')\n",
    "    threshold_business, best_business = find_optimal_threshold(y_test, y_pred_proba, metric='business')\n",
    "    \n",
    "    # Use business-optimized threshold\n",
    "    optimal_threshold = threshold_business\n",
    "    y_pred_optimal = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "    \n",
    "    # Standard threshold predictions for comparison\n",
    "    y_pred_standard = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "    auc_pr = auc(recall_vals, precision_vals)\n",
    "    \n",
    "    # Classification reports\n",
    "    report_standard = classification_report(y_test, y_pred_standard, output_dict=True)\n",
    "    report_optimal = classification_report(y_test, y_pred_optimal, output_dict=True)\n",
    "    \n",
    "    # Business metrics\n",
    "    business_metrics_standard = calculate_business_metrics(y_test, y_pred_standard, y_pred_proba)\n",
    "    business_metrics_optimal = calculate_business_metrics(y_test, y_pred_optimal, y_pred_proba)\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"AUC-ROC\": auc_roc,\n",
    "        \"AUC-PR\": auc_pr,\n",
    "        \"CV_AUC_Mean\": cv_results[name]['auc_mean'],\n",
    "        \"CV_AUC_Std\": cv_results[name]['auc_std'],\n",
    "        \"Recall_Standard\": report_standard['1']['recall'],\n",
    "        \"Precision_Standard\": report_standard['1']['precision'],\n",
    "        \"F1_Standard\": report_standard['1']['f1-score'],\n",
    "        \"Recall_Optimal\": report_optimal['1']['recall'],\n",
    "        \"Precision_Optimal\": report_optimal['1']['precision'],\n",
    "        \"F1_Optimal\": report_optimal['1']['f1-score'],\n",
    "        \"Optimal_Threshold\": optimal_threshold,\n",
    "        \"Defaults_Missed_Standard\": business_metrics_standard['defaults_missed'],\n",
    "        \"Defaults_Missed_Optimal\": business_metrics_optimal['defaults_missed'],\n",
    "        \"Total_Cost_Standard\": business_metrics_standard['total_cost'],\n",
    "        \"Total_Cost_Optimal\": business_metrics_optimal['total_cost'],\n",
    "        \"Net_Savings_Optimal\": business_metrics_optimal['net_savings'],\n",
    "        \"ROI_Optimal\": business_metrics_optimal['roi'],\n",
    "        \"Training_Time\": training_time\n",
    "    })\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\nüìä Model Performance:\")\n",
    "    print(f\"  AUC-ROC: {auc_roc:.4f}\")\n",
    "    print(f\"  AUC-PR: {auc_pr:.4f}\")\n",
    "    \n",
    "    print(f\"\\nüìä Standard Threshold (0.5):\")\n",
    "    print(f\"  Recall: {report_standard['1']['recall']:.2%}\")\n",
    "    print(f\"  Precision: {report_standard['1']['precision']:.2%}\")\n",
    "    print(f\"  F1-Score: {report_standard['1']['f1-score']:.4f}\")\n",
    "    print(f\"  Defaults Missed: {business_metrics_standard['defaults_missed']:,}\")\n",
    "    print(f\"  Total Cost: ${business_metrics_standard['total_cost']:,.0f}\")\n",
    "    \n",
    "    print(f\"\\nüìä Optimal Threshold ({optimal_threshold:.3f}):\")\n",
    "    print(f\"  Recall: {report_optimal['1']['recall']:.2%}\")\n",
    "    print(f\"  Precision: {report_optimal['1']['precision']:.2%}\")\n",
    "    print(f\"  F1-Score: {report_optimal['1']['f1-score']:.4f}\")\n",
    "    print(f\"  Defaults Missed: {business_metrics_optimal['defaults_missed']:,}\")\n",
    "    print(f\"  Total Cost: ${business_metrics_optimal['total_cost']:,.0f}\")\n",
    "    print(f\"  Net Savings: ${business_metrics_optimal['net_savings']:,.0f}\")\n",
    "    print(f\"  ROI: {business_metrics_optimal['roi']:.1f}%\")\n",
    "    \n",
    "    # Store model with optimal threshold\n",
    "    model.optimal_threshold = optimal_threshold\n",
    "    trained_models[name] = model\n",
    "    \n",
    "    # Perform SHAP analysis\n",
    "    perform_shap_analysis(model, X_train, X_test, name)\n",
    "\n",
    "# =====================================================================\n",
    "# STEP 5: MODEL CALIBRATION\n",
    "# =====================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üéØ CALIBRATING MODELS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "calibrated_models = {}\n",
    "calibrated_probas = {}\n",
    "\n",
    "for name, model in trained_models.items():\n",
    "    print(f\"\\nCalibrating {name}...\")\n",
    "    \n",
    "    # Calibrate model using isotonic regression\n",
    "    calibrated = CalibratedClassifierCV(model, method='isotonic', cv=3)\n",
    "    calibrated.fit(X_train, y_train)\n",
    "    \n",
    "    # Get calibrated probabilities\n",
    "    calibrated_proba = calibrated.predict_proba(X_test)[:, 1]\n",
    "    calibrated_probas[name] = calibrated_proba\n",
    "    \n",
    "    # Compare calibration\n",
    "    original_score = roc_auc_score(y_test, probas_dict[name])\n",
    "    calibrated_score = roc_auc_score(y_test, calibrated_proba)\n",
    "    \n",
    "    print(f\"  Original AUC: {original_score:.4f}\")\n",
    "    print(f\"  Calibrated AUC: {calibrated_score:.4f}\")\n",
    "    print(f\"  Improvement: {calibrated_score - original_score:+.4f}\")\n",
    "    \n",
    "    calibrated_models[name] = calibrated\n",
    "\n",
    "# =====================================================================\n",
    "# STEP 6: GENERATE VISUALIZATIONS\n",
    "# =====================================================================\n",
    "print(\"\\nüìà Generating visualizations...\")\n",
    "\n",
    "# Plot calibration curves\n",
    "plot_calibration_curve(y_test, probas_dict, 'artifacts/plots/calibration_curves.png')\n",
    "plot_calibration_curve(y_test, calibrated_probas, 'artifacts/plots/calibration_curves_calibrated.png')\n",
    "\n",
    "# Plot ROC curves\n",
    "plot_roc_curves(y_test, probas_dict, 'artifacts/plots/roc_curves.png')\n",
    "\n",
    "# Plot model comparison\n",
    "results_df = pd.DataFrame(results)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# AUC comparison\n",
    "ax = axes[0, 0]\n",
    "results_df.plot(x='Model', y=['AUC-ROC', 'AUC-PR'], kind='bar', ax=ax)\n",
    "ax.set_title('Model Performance - AUC Scores', fontsize=14)\n",
    "ax.set_ylabel('Score')\n",
    "ax.legend(['AUC-ROC', 'AUC-PR'])\n",
    "ax.set_ylim([0, 1])\n",
    "\n",
    "# Cost comparison\n",
    "ax = axes[0, 1]\n",
    "cost_data = results_df[['Model', 'Total_Cost_Standard', 'Total_Cost_Optimal']].set_index('Model')\n",
    "cost_data.plot(kind='bar', ax=ax)\n",
    "ax.set_title('Total Cost Comparison', fontsize=14)\n",
    "ax.set_ylabel('Cost ($)')\n",
    "ax.legend(['Standard Threshold', 'Optimal Threshold'])\n",
    "\n",
    "# Defaults missed comparison\n",
    "ax = axes[1, 0]\n",
    "defaults_data = results_df[['Model', 'Defaults_Missed_Standard', 'Defaults_Missed_Optimal']].set_index('Model')\n",
    "defaults_data.plot(kind='bar', ax=ax)\n",
    "ax.set_title('Defaults Missed Comparison', fontsize=14)\n",
    "ax.set_ylabel('Count')\n",
    "ax.legend(['Standard Threshold', 'Optimal Threshold'])\n",
    "\n",
    "# ROI comparison\n",
    "ax = axes[1, 1]\n",
    "results_df.plot(x='Model', y='ROI_Optimal', kind='bar', ax=ax, legend=False)\n",
    "ax.set_title('Return on Investment (Optimal Threshold)', fontsize=14)\n",
    "ax.set_ylabel('ROI (%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/plots/model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# =====================================================================\n",
    "# STEP 7: SAVE MODELS AND RESULTS\n",
    "# =====================================================================\n",
    "print(\"\\nüíæ Saving models and results...\")\n",
    "\n",
    "# Save models\n",
    "for name, model in trained_models.items():\n",
    "    model_path = f\"artifacts/models/{name.replace(' ', '_').lower()}.pkl\"\n",
    "    joblib.dump(model, model_path)\n",
    "    print(f\"  ‚úì Saved {name} ‚Üí {model_path}\")\n",
    "\n",
    "# Save calibrated models\n",
    "for name, model in calibrated_models.items():\n",
    "    model_path = f\"artifacts/models/{name.replace(' ', '_').lower()}_calibrated.pkl\"\n",
    "    joblib.dump(model, model_path)\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv(\"artifacts/reports/model_results_enhanced.csv\", index=False)\n",
    "cv_df.to_csv(\"artifacts/reports/cross_validation_results.csv\")\n",
    "\n",
    "# Save optimal thresholds\n",
    "thresholds_df = pd.DataFrame([\n",
    "    {\n",
    "        'Model': name, \n",
    "        'Optimal_Threshold': model.optimal_threshold,\n",
    "        'Metric_Optimized': 'business_cost'\n",
    "    } \n",
    "    for name, model in trained_models.items()\n",
    "])\n",
    "thresholds_df.to_csv(\"artifacts/reports/optimal_thresholds.csv\", index=False)\n",
    "\n",
    "# =====================================================================\n",
    "# STEP 8: GENERATE FINAL REPORT\n",
    "# =====================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üìä FINAL MODEL COMPARISON REPORT\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Sort by net savings\n",
    "results_df_sorted = results_df.sort_values('Net_Savings_Optimal', ascending=False)\n",
    "\n",
    "print(\"\\nüèÜ Model Rankings by Net Savings:\")\n",
    "for idx, row in results_df_sorted.iterrows():\n",
    "    print(f\"\\n{idx+1}. {row['Model']}\")\n",
    "    print(f\"   Net Savings: ${row['Net_Savings_Optimal']:,.0f}\")\n",
    "    print(f\"   ROI: {row['ROI_Optimal']:.1f}%\")\n",
    "    print(f\"   AUC-ROC: {row['AUC-ROC']:.4f} (CV: {row['CV_AUC_Mean']:.4f} ¬± {row['CV_AUC_Std']:.4f})\")\n",
    "    print(f\"   Optimal Threshold: {row['Optimal_Threshold']:.3f}\")\n",
    "    print(f\"   Cost Reduction: ${row['Total_Cost_Standard'] - row['Total_Cost_Optimal']:,.0f}\")\n",
    "\n",
    "best_model = results_df_sorted.iloc[0]\n",
    "print(f\"\\nüéØ RECOMMENDED MODEL: {best_model['Model']}\")\n",
    "print(f\"   Expected Annual Savings: ${best_model['Net_Savings_Optimal'] * 12:,.0f}\")\n",
    "print(f\"   Defaults Caught: {(best_model['Recall_Optimal'] * 100):.1f}%\")\n",
    "print(f\"   False Alarm Rate: {(1 - best_model['Precision_Optimal']) * 100:.1f}%\")\n",
    "\n",
    "# Create executive summary\n",
    "summary = {\n",
    "    'Best_Model': best_model['Model'],\n",
    "    'Annual_Savings': best_model['Net_Savings_Optimal'] * 12,\n",
    "    'ROI': best_model['ROI_Optimal'],\n",
    "    'Defaults_Prevented_Rate': best_model['Recall_Optimal'] * 100,\n",
    "    'Investigation_Accuracy': best_model['Precision_Optimal'] * 100,\n",
    "    'Optimal_Threshold': best_model['Optimal_Threshold'],\n",
    "    'Implementation_Recommendation': 'Deploy with continuous monitoring and monthly recalibration'\n",
    "}\n",
    "\n",
    "pd.DataFrame([summary]).to_csv('artifacts/reports/executive_summary.csv', index=False)\n",
    "\n",
    "print(\"\\n‚úÖ Enhanced training pipeline completed successfully!\")\n",
    "print(f\"üìÅ All artifacts saved in 'artifacts/' directory\")\n",
    "print(f\"üìä Check 'artifacts/shap/' for feature importance visualizations\")\n",
    "print(f\"üìà Check 'artifacts/plots/' for performance visualizations\")\n",
    "print(f\"üìã Check 'artifacts/reports/' for detailed reports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23214741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a4a351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e557d68",
   "metadata": {},
   "source": [
    "### With Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ce90c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üî¨ SMOTE IMPACT ANALYSIS ON BUSINESS METRICS\n",
      "================================================================================\n",
      "\n",
      "üì• Loading data...\n",
      "Training set: (97484, 67)\n",
      "Original class distribution: [89608  7876]\n",
      "Original imbalance ratio: 11.4:1\n",
      "\n",
      "üîÑ Testing different SMOTE configurations...\n",
      "================================================================================\n",
      "\n",
      "üìä Testing Logistic Regression...\n",
      "  ‚Üí No SMOTE... AUC: 0.7328, F1@0.5: 0.0150, Optimal Cost: $22,403,000\n",
      "  ‚Üí SMOTE 1:1... AUC: 0.7298, F1@0.5: 0.2499, Optimal Cost: $22,403,000\n",
      "  ‚Üí SMOTE 2:1... AUC: 0.7306, F1@0.5: 0.2731, Optimal Cost: $22,403,000\n",
      "  ‚Üí SMOTE 5:1... AUC: 0.7319, F1@0.5: 0.1493, Optimal Cost: $22,403,000\n",
      "\n",
      "üìä Testing XGBoost...\n",
      "  ‚Üí No SMOTE... AUC: 0.7583, F1@0.5: 0.0937, Optimal Cost: $22,403,000\n",
      "  ‚Üí SMOTE 1:1... AUC: 0.6779, F1@0.5: 0.1939, Optimal Cost: $22,349,000\n",
      "  ‚Üí SMOTE 2:1... AUC: 0.6741, F1@0.5: 0.2226, Optimal Cost: $22,334,000\n",
      "  ‚Üí SMOTE 5:1... AUC: 0.7000, F1@0.5: 0.2389, Optimal Cost: $22,403,000\n",
      "\n",
      "üìä Testing LightGBM...\n",
      "  ‚Üí No SMOTE... AUC: 0.7592, F1@0.5: 0.0276, Optimal Cost: $22,403,000\n",
      "  ‚Üí SMOTE 1:1... AUC: 0.6702, F1@0.5: 0.2106, Optimal Cost: $22,403,000\n",
      "  ‚Üí SMOTE 2:1... AUC: 0.6784, F1@0.5: 0.2303, Optimal Cost: $22,399,000\n",
      "  ‚Üí SMOTE 5:1... AUC: 0.7013, F1@0.5: 0.2343, Optimal Cost: $22,390,000\n",
      "\n",
      "üìä Creating comparison visualizations...\n",
      "\n",
      "================================================================================\n",
      "üìã DETAILED RESULTS COMPARISON\n",
      "================================================================================\n",
      "\n",
      "üîπ Logistic Regression:\n",
      "\n",
      "  Metrics at Standard Threshold (0.5):\n",
      "  SMOTE Config    Precision  Recall     F1 Score   Cost           \n",
      "  ------------------------------------------------------------\n",
      "  No SMOTE        41.67%     0.76%      0.0150     $  615,531,000\n",
      "  SMOTE 1:1       15.50%     64.50%     0.2499     $  227,110,000\n",
      "  SMOTE 2:1       21.43%     37.63%     0.2731     $  389,536,000\n",
      "  SMOTE 5:1       32.99%     9.65%      0.1493     $  560,771,000\n",
      "\n",
      "  Metrics at Business-Optimal Threshold:\n",
      "  SMOTE Config    Threshold  Recall     Missed     Net Savings    \n",
      "  ------------------------------------------------------------\n",
      "  No SMOTE        0.000      100.00%    0          $  597,832,000\n",
      "  SMOTE 1:1       0.000      100.00%    0          $  597,832,000\n",
      "  SMOTE 2:1       0.000      100.00%    0          $  597,832,000\n",
      "  SMOTE 5:1       0.000      100.00%    0          $  597,832,000\n",
      "\n",
      "üîπ XGBoost:\n",
      "\n",
      "  Metrics at Standard Threshold (0.5):\n",
      "  SMOTE Config    Precision  Recall     F1 Score   Cost           \n",
      "  ------------------------------------------------------------\n",
      "  No SMOTE        54.30%     5.13%      0.0937     $  588,505,000\n",
      "  SMOTE 1:1       11.19%     72.83%     0.1939     $  179,910,000\n",
      "  SMOTE 2:1       13.88%     56.22%     0.2226     $  278,400,000\n",
      "  SMOTE 5:1       17.54%     37.43%     0.2389     $  391,544,000\n",
      "\n",
      "  Metrics at Business-Optimal Threshold:\n",
      "  SMOTE Config    Threshold  Recall     Missed     Net Savings    \n",
      "  ------------------------------------------------------------\n",
      "  No SMOTE        0.000      100.00%    0          $  597,832,000\n",
      "  SMOTE 1:1       0.006      100.00%    0          $  597,886,000\n",
      "  SMOTE 2:1       0.003      100.00%    0          $  597,901,000\n",
      "  SMOTE 5:1       0.000      100.00%    0          $  597,832,000\n",
      "\n",
      "üîπ LightGBM:\n",
      "\n",
      "  Metrics at Standard Threshold (0.5):\n",
      "  SMOTE Config    Precision  Recall     F1 Score   Cost           \n",
      "  ------------------------------------------------------------\n",
      "  No SMOTE        46.67%     1.42%      0.0276     $  611,447,000\n",
      "  SMOTE 1:1       12.99%     55.51%     0.2106     $  283,258,000\n",
      "  SMOTE 2:1       15.97%     41.24%     0.2303     $  368,726,000\n",
      "  SMOTE 5:1       21.82%     25.29%     0.2343     $  465,149,000\n",
      "\n",
      "  Metrics at Business-Optimal Threshold:\n",
      "  SMOTE Config    Threshold  Recall     Missed     Net Savings    \n",
      "  ------------------------------------------------------------\n",
      "  No SMOTE        0.000      100.00%    0          $  597,832,000\n",
      "  SMOTE 1:1       0.000      100.00%    0          $  597,832,000\n",
      "  SMOTE 2:1       0.007      100.00%    0          $  597,836,000\n",
      "  SMOTE 5:1       0.006      100.00%    0          $  597,845,000\n",
      "\n",
      "================================================================================\n",
      "üîç KEY INSIGHTS\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Best F1 Score at threshold 0.5:\n",
      "   Model: Logistic Regression with SMOTE 2:1\n",
      "   F1 Score: 0.2731\n",
      "   Precision: 21.43%, Recall: 37.63%\n",
      "\n",
      "üí∞ Best Business Value (Net Savings):\n",
      "   Model: XGBoost with SMOTE 2:1\n",
      "   Net Savings: $597,901,000\n",
      "   Optimal Threshold: 0.003\n",
      "   Missed Defaults: 0\n",
      "\n",
      "================================================================================\n",
      "üí° BUSINESS RECOMMENDATION\n",
      "================================================================================\n",
      "\n",
      "‚úÖ SMOTE provides marginal improvement\n",
      "   Additional savings: $69,000\n",
      "   Best config: SMOTE 2:1\n",
      "\n",
      "üìå Key Findings:\n",
      "1. SMOTE improves F1 scores at standard threshold (0.5)\n",
      "2. Business-optimal threshold remains very low regardless of SMOTE\n",
      "3. Net savings are dominated by the 315:1 cost ratio, not class balance\n",
      "4. SMOTE adds training complexity without significant business value\n",
      "\n",
      "‚úÖ Analysis complete! Check artifacts/plots/smote_impact_analysis.png\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SMOTE Analysis for Loan Default Prediction\n",
    "=========================================\n",
    "This script tests whether SMOTE improves business metrics for the loan default model.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, precision_recall_curve, classification_report,\n",
    "    confusion_matrix, f1_score, roc_curve, auc\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "RANDOM_SEED = 42\n",
    "DEFAULT_COST = 315000\n",
    "INVESTIGATION_COST = 1000\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üî¨ SMOTE IMPACT ANALYSIS ON BUSINESS METRICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load data\n",
    "print(\"\\nüì• Loading data...\")\n",
    "X_train = pd.read_csv('processed_data/X_train_encoded.csv')\n",
    "X_test = pd.read_csv('processed_data/X_test_encoded.csv')\n",
    "y_train = pd.read_csv('processed_data/y_train.csv').values.ravel()\n",
    "y_test = pd.read_csv('processed_data/y_test.csv').values.ravel()\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Original class distribution: {np.bincount(y_train)}\")\n",
    "print(f\"Original imbalance ratio: {np.bincount(y_train)[0]/np.bincount(y_train)[1]:.1f}:1\")\n",
    "\n",
    "# Function to calculate business metrics\n",
    "def calculate_business_metrics(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    if cm.shape[0] > 1:\n",
    "        fn = cm[1,0]  # missed defaults\n",
    "        fp = cm[0,1]  # false alarms\n",
    "    else:\n",
    "        fn = sum(y_true) if y_pred[0] == 0 else 0\n",
    "        fp = 0\n",
    "    \n",
    "    total_cost = (fn * DEFAULT_COST) + (fp * INVESTIGATION_COST)\n",
    "    return {\n",
    "        'missed_defaults': fn,\n",
    "        'false_alarms': fp,\n",
    "        'total_cost': total_cost,\n",
    "        'cost_per_application': total_cost / len(y_true)\n",
    "    }\n",
    "\n",
    "# Function to find optimal threshold\n",
    "def find_optimal_threshold(y_true, y_scores):\n",
    "    thresholds = np.linspace(0, 1, 1000)\n",
    "    best_cost = float('inf')\n",
    "    best_threshold = 0.5\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_scores >= threshold).astype(int)\n",
    "        metrics = calculate_business_metrics(y_true, y_pred)\n",
    "        \n",
    "        if metrics['total_cost'] < best_cost:\n",
    "            best_cost = metrics['total_cost']\n",
    "            best_threshold = threshold\n",
    "    \n",
    "    return best_threshold, best_cost\n",
    "\n",
    "# Models to test\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=RANDOM_SEED),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        random_state=RANDOM_SEED,\n",
    "        eval_metric='auc',\n",
    "        verbosity=0\n",
    "    ),\n",
    "    \"LightGBM\": LGBMClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        random_state=RANDOM_SEED,\n",
    "        verbose=-1\n",
    "    )\n",
    "}\n",
    "\n",
    "# Test different SMOTE ratios\n",
    "smote_ratios = {\n",
    "    'No SMOTE': None,\n",
    "    'SMOTE 1:1': 1.0,\n",
    "    'SMOTE 2:1': 0.5,\n",
    "    'SMOTE 5:1': 0.2\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"\\nüîÑ Testing different SMOTE configurations...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for model_name, base_model in models.items():\n",
    "    print(f\"\\nüìä Testing {model_name}...\")\n",
    "    \n",
    "    for smote_name, sampling_ratio in smote_ratios.items():\n",
    "        print(f\"  ‚Üí {smote_name}...\", end=' ')\n",
    "        \n",
    "        # Create pipeline with or without SMOTE\n",
    "        if sampling_ratio is None:\n",
    "            # No SMOTE\n",
    "            model = base_model\n",
    "            X_train_processed = X_train\n",
    "            y_train_processed = y_train\n",
    "        else:\n",
    "            # With SMOTE\n",
    "            smote = SMOTE(sampling_strategy=sampling_ratio, random_state=RANDOM_SEED)\n",
    "            X_train_processed, y_train_processed = smote.fit_resample(X_train, y_train)\n",
    "        \n",
    "        # Train model\n",
    "        model = base_model.__class__(**base_model.get_params())\n",
    "        model.fit(X_train_processed, y_train_processed)\n",
    "        \n",
    "        # Predictions\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        y_pred_default = model.predict(X_test)\n",
    "        \n",
    "        # Find optimal threshold\n",
    "        optimal_threshold, optimal_cost = find_optimal_threshold(y_test, y_pred_proba)\n",
    "        y_pred_optimal = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "        \n",
    "        # Metrics at default threshold (0.5)\n",
    "        report_default = classification_report(y_test, y_pred_default, output_dict=True)\n",
    "        metrics_default = calculate_business_metrics(y_test, y_pred_default)\n",
    "        \n",
    "        # Metrics at optimal threshold\n",
    "        report_optimal = classification_report(y_test, y_pred_optimal, output_dict=True)\n",
    "        metrics_optimal = calculate_business_metrics(y_test, y_pred_optimal)\n",
    "        \n",
    "        # Store results\n",
    "        result = {\n",
    "            'Model': model_name,\n",
    "            'SMOTE_Config': smote_name,\n",
    "            'Train_Size': len(y_train_processed),\n",
    "            'Train_Ratio': f\"{np.bincount(y_train_processed)[0]/np.bincount(y_train_processed)[1]:.1f}:1\",\n",
    "            'AUC': auc_score,\n",
    "            # Default threshold (0.5) metrics\n",
    "            'Precision_0.5': report_default['1']['precision'],\n",
    "            'Recall_0.5': report_default['1']['recall'],\n",
    "            'F1_0.5': report_default['1']['f1-score'],\n",
    "            'Cost_0.5': metrics_default['total_cost'],\n",
    "            'Missed_Defaults_0.5': metrics_default['missed_defaults'],\n",
    "            # Optimal threshold metrics\n",
    "            'Optimal_Threshold': optimal_threshold,\n",
    "            'Precision_Opt': report_optimal['1']['precision'],\n",
    "            'Recall_Opt': report_optimal['1']['recall'],\n",
    "            'F1_Opt': report_optimal['1']['f1-score'],\n",
    "            'Cost_Opt': metrics_optimal['total_cost'],\n",
    "            'Missed_Defaults_Opt': metrics_optimal['missed_defaults'],\n",
    "            # Business metrics\n",
    "            'Cost_Reduction': metrics_default['total_cost'] - metrics_optimal['total_cost'],\n",
    "            'Net_Savings': (sum(y_test) * DEFAULT_COST) - metrics_optimal['total_cost']\n",
    "        }\n",
    "        results.append(result)\n",
    "        print(f\"AUC: {auc_score:.4f}, F1@0.5: {report_default['1']['f1-score']:.4f}, \"\n",
    "              f\"Optimal Cost: ${metrics_optimal['total_cost']:,.0f}\")\n",
    "\n",
    "# Create results dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Visualization\n",
    "print(\"\\nüìä Creating comparison visualizations...\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('SMOTE Impact Analysis on Loan Default Prediction', fontsize=16)\n",
    "\n",
    "# 1. F1 Score at 0.5 threshold\n",
    "ax = axes[0, 0]\n",
    "pivot_f1 = results_df.pivot(index='SMOTE_Config', columns='Model', values='F1_0.5')\n",
    "pivot_f1.plot(kind='bar', ax=ax)\n",
    "ax.set_title('F1 Score at Default Threshold (0.5)')\n",
    "ax.set_ylabel('F1 Score')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# 2. Optimal threshold values\n",
    "ax = axes[0, 1]\n",
    "pivot_threshold = results_df.pivot(index='SMOTE_Config', columns='Model', values='Optimal_Threshold')\n",
    "pivot_threshold.plot(kind='bar', ax=ax)\n",
    "ax.set_title('Business-Optimal Threshold by SMOTE Config')\n",
    "ax.set_ylabel('Optimal Threshold')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# 3. Total cost at optimal threshold\n",
    "ax = axes[0, 2]\n",
    "pivot_cost = results_df.pivot(index='SMOTE_Config', columns='Model', values='Cost_Opt')\n",
    "pivot_cost.plot(kind='bar', ax=ax)\n",
    "ax.set_title('Total Cost at Optimal Threshold')\n",
    "ax.set_ylabel('Cost ($)')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# 4. Recall at optimal threshold\n",
    "ax = axes[1, 0]\n",
    "pivot_recall = results_df.pivot(index='SMOTE_Config', columns='Model', values='Recall_Opt')\n",
    "pivot_recall.plot(kind='bar', ax=ax)\n",
    "ax.set_title('Recall at Business-Optimal Threshold')\n",
    "ax.set_ylabel('Recall')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# 5. Missed defaults comparison\n",
    "ax = axes[1, 1]\n",
    "pivot_missed = results_df.pivot(index='SMOTE_Config', columns='Model', values='Missed_Defaults_Opt')\n",
    "pivot_missed.plot(kind='bar', ax=ax)\n",
    "ax.set_title('Missed Defaults at Optimal Threshold')\n",
    "ax.set_ylabel('Count')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# 6. Net savings\n",
    "ax = axes[1, 2]\n",
    "pivot_savings = results_df.pivot(index='SMOTE_Config', columns='Model', values='Net_Savings')\n",
    "pivot_savings.plot(kind='bar', ax=ax)\n",
    "ax.set_title('Net Savings (Business Value)')\n",
    "ax.set_ylabel('Savings ($)')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/plots/smote_impact_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Detailed comparison table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìã DETAILED RESULTS COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Group by model and show metrics\n",
    "for model_name in models.keys():\n",
    "    print(f\"\\nüîπ {model_name}:\")\n",
    "    model_results = results_df[results_df['Model'] == model_name]\n",
    "    \n",
    "    print(\"\\n  Metrics at Standard Threshold (0.5):\")\n",
    "    print(f\"  {'SMOTE Config':<15} {'Precision':<10} {'Recall':<10} {'F1 Score':<10} {'Cost':<15}\")\n",
    "    print(\"  \" + \"-\"*60)\n",
    "    for _, row in model_results.iterrows():\n",
    "        print(f\"  {row['SMOTE_Config']:<15} {row['Precision_0.5']:<10.2%} {row['Recall_0.5']:<10.2%} \"\n",
    "              f\"{row['F1_0.5']:<10.4f} ${row['Cost_0.5']:>13,.0f}\")\n",
    "    \n",
    "    print(\"\\n  Metrics at Business-Optimal Threshold:\")\n",
    "    print(f\"  {'SMOTE Config':<15} {'Threshold':<10} {'Recall':<10} {'Missed':<10} {'Net Savings':<15}\")\n",
    "    print(\"  \" + \"-\"*60)\n",
    "    for _, row in model_results.iterrows():\n",
    "        print(f\"  {row['SMOTE_Config']:<15} {row['Optimal_Threshold']:<10.3f} {row['Recall_Opt']:<10.2%} \"\n",
    "              f\"{row['Missed_Defaults_Opt']:<10.0f} ${row['Net_Savings']:>13,.0f}\")\n",
    "\n",
    "# Save detailed results\n",
    "results_df.to_csv('artifacts/reports/smote_comparison_results.csv', index=False)\n",
    "\n",
    "# Key insights\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üîç KEY INSIGHTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find best configuration for different objectives\n",
    "best_f1 = results_df.loc[results_df['F1_0.5'].idxmax()]\n",
    "best_business = results_df.loc[results_df['Net_Savings'].idxmax()]\n",
    "\n",
    "print(f\"\\n‚úÖ Best F1 Score at threshold 0.5:\")\n",
    "print(f\"   Model: {best_f1['Model']} with {best_f1['SMOTE_Config']}\")\n",
    "print(f\"   F1 Score: {best_f1['F1_0.5']:.4f}\")\n",
    "print(f\"   Precision: {best_f1['Precision_0.5']:.2%}, Recall: {best_f1['Recall_0.5']:.2%}\")\n",
    "\n",
    "print(f\"\\nüí∞ Best Business Value (Net Savings):\")\n",
    "print(f\"   Model: {best_business['Model']} with {best_business['SMOTE_Config']}\")\n",
    "print(f\"   Net Savings: ${best_business['Net_Savings']:,.0f}\")\n",
    "print(f\"   Optimal Threshold: {best_business['Optimal_Threshold']:.3f}\")\n",
    "print(f\"   Missed Defaults: {best_business['Missed_Defaults_Opt']:.0f}\")\n",
    "\n",
    "# Business recommendation\n",
    "no_smote_best = results_df[results_df['SMOTE_Config'] == 'No SMOTE'].loc[\n",
    "    results_df[results_df['SMOTE_Config'] == 'No SMOTE']['Net_Savings'].idxmax()\n",
    "]\n",
    "smote_best = results_df[results_df['SMOTE_Config'] != 'No SMOTE'].loc[\n",
    "    results_df[results_df['SMOTE_Config'] != 'No SMOTE']['Net_Savings'].idxmax()\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üí° BUSINESS RECOMMENDATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if no_smote_best['Net_Savings'] >= smote_best['Net_Savings']:\n",
    "    print(\"\\n‚ùå DO NOT USE SMOTE for this business case!\")\n",
    "    print(f\"   No SMOTE achieves the same or better business value\")\n",
    "    print(f\"   Both achieve ~${no_smote_best['Net_Savings']/1e6:.0f}M in savings\")\n",
    "    print(f\"   SMOTE adds complexity without improving business metrics\")\n",
    "else:\n",
    "    savings_diff = smote_best['Net_Savings'] - no_smote_best['Net_Savings']\n",
    "    print(f\"\\n‚úÖ SMOTE provides marginal improvement\")\n",
    "    print(f\"   Additional savings: ${savings_diff:,.0f}\")\n",
    "    print(f\"   Best config: {smote_best['SMOTE_Config']}\")\n",
    "\n",
    "print(\"\\nüìå Key Findings:\")\n",
    "print(\"1. SMOTE improves F1 scores at standard threshold (0.5)\")\n",
    "print(\"2. Business-optimal threshold remains very low regardless of SMOTE\")\n",
    "print(\"3. Net savings are dominated by the 315:1 cost ratio, not class balance\")\n",
    "print(\"4. SMOTE adds training complexity without significant business value\")\n",
    "\n",
    "print(\"\\n‚úÖ Analysis complete! Check artifacts/plots/smote_impact_analysis.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "630a62c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "üè¶ LOAN DEFAULT PREDICTION - BALANCED BOOSTING PIPELINE (SMOTETomek)\n",
      "====================================================================================================\n",
      "Training data: (97484, 56), Imbalance: 11.4:1\n",
      "\n",
      "‚öñÔ∏è Balancing the training data using SMOTETomek...\n",
      "Balanced data shape: (116490, 56)\n",
      "New ratio: 3.33:1\n",
      "\n",
      "====================================================================================================\n",
      "üöÄ Training XGBoost (Balanced)\n",
      "====================================================================================================\n",
      "üéØ AUC-ROC: 0.7695 | AUC-PR: 0.2613\n",
      "üìà Recall: 3.00% | Precision: 57.84% | F1: 0.057\n",
      "‚è±Ô∏è Training Time: 6.86s\n",
      "\n",
      "====================================================================================================\n",
      "üöÄ Training LightGBM (Balanced)\n",
      "====================================================================================================\n",
      "üéØ AUC-ROC: 0.7648 | AUC-PR: 0.2477\n",
      "üìà Recall: 2.95% | Precision: 58.00% | F1: 0.056\n",
      "‚è±Ô∏è Training Time: 4.68s\n",
      "\n",
      "üìä Final Summary:\n",
      "                 Model   AUC-ROC    AUC-PR    Recall  Precision        F1  \\\n",
      "0   XGBoost (Balanced)  0.769467  0.261314  0.029964   0.578431  0.056977   \n",
      "1  LightGBM (Balanced)  0.764772  0.247690  0.029457   0.580000  0.056066   \n",
      "\n",
      "   Train Time (s)  \n",
      "0            6.86  \n",
      "1            4.68  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import warnings, time\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"üè¶ LOAN DEFAULT PREDICTION - BALANCED BOOSTING PIPELINE (SMOTETomek)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# ===============================================================\n",
    "# STEP 1: Load Data\n",
    "# ===============================================================\n",
    "X_train = pd.read_csv('processed_data/X_train_encoded.csv')\n",
    "X_test = pd.read_csv('processed_data/X_test_encoded.csv')\n",
    "y_train = pd.read_csv('processed_data/y_train.csv').values.ravel()\n",
    "y_test = pd.read_csv('processed_data/y_test.csv').values.ravel()\n",
    "\n",
    "print(f\"Training data: {X_train.shape}, Imbalance: {(y_train==0).sum()/(y_train==1).sum():.1f}:1\")\n",
    "\n",
    "# ===============================================================\n",
    "# STEP 2: SMOTETomek Resampling on Training Data\n",
    "# ===============================================================\n",
    "print(\"\\n‚öñÔ∏è Balancing the training data using SMOTETomek...\")\n",
    "# smt = SMOTETomek(random_state=42, sampling_strategy=0.5)  # target 1:2 ratio\n",
    "# X_train_bal, y_train_bal = smt.fit_resample(X_train, y_train)\n",
    "\n",
    "smote = SMOTE(random_state=42, sampling_strategy=0.3)  # Don't fully balance\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_encoded, y_train)\n",
    "\n",
    "\n",
    "print(f\"Balanced data shape: {X_train_resampled.shape}\")\n",
    "print(f\"New ratio: {(y_train_resampled==0).sum()/(y_train_resampled==1).sum():.2f}:1\")\n",
    "\n",
    "# ===============================================================\n",
    "# STEP 3: Train Models\n",
    "# ===============================================================\n",
    "models = {\n",
    "    \"XGBoost (Balanced)\": XGBClassifier(\n",
    "        scale_pos_weight=1.0,  # already balanced\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        n_estimators=600,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        eval_metric='auc',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \"LightGBM (Balanced)\": LGBMClassifier(\n",
    "        is_unbalance=False,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        n_estimators=600,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(f\"üöÄ Training {name}\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    start = time.time()\n",
    "    model.fit(X_train_resampled, y_train_resampled) # xgb_model.fit(X_train_resampled, y_train_resampled)\n",
    "    dur = time.time() - start\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    auc_roc = roc_auc_score(y_test, y_proba)\n",
    "    prec, rec, _ = precision_recall_curve(y_test, y_proba)\n",
    "    auc_pr = auc(rec, prec)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"AUC-ROC\": auc_roc,\n",
    "        \"AUC-PR\": auc_pr,\n",
    "        \"Recall\": report['1']['recall'],\n",
    "        \"Precision\": report['1']['precision'],\n",
    "        \"F1\": report['1']['f1-score'],\n",
    "        \"Train Time (s)\": round(dur, 2)\n",
    "    })\n",
    "    \n",
    "    print(f\"üéØ AUC-ROC: {auc_roc:.4f} | AUC-PR: {auc_pr:.4f}\")\n",
    "    print(f\"üìà Recall: {report['1']['recall']:.2%} | Precision: {report['1']['precision']:.2%} | F1: {report['1']['f1-score']:.3f}\")\n",
    "    print(f\"‚è±Ô∏è Training Time: {dur:.2f}s\")\n",
    "\n",
    "# ===============================================================\n",
    "# STEP 4: Save Results\n",
    "# ===============================================================\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nüìä Final Summary:\")\n",
    "print(results_df)\n",
    "joblib.dump(models, \"artifacts/tuned_models/balanced_boosting.pkl\")\n",
    "results_df.to_csv(\"artifacts/tuned_models/balanced_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab387fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üè¶ LOAN DEFAULT PREDICTION - IMPROVED SMOTE PIPELINE\n",
      "================================================================================\n",
      "Training data: (97484, 56), Imbalance: 11.4:1\n",
      "\n",
      "‚öñÔ∏è Applying SMOTE with conservative ratio...\n",
      "‚úì Balanced data shape: (116490, 56)\n",
      "‚úì New ratio: 3.33:1\n",
      "‚úì Class distribution: [89608 26882]\n",
      "\n",
      "================================================================================\n",
      "üöÄ Training XGBoost (SMOTE + Tuned)\n",
      "================================================================================\n",
      "\n",
      "üéØ Finding Optimal Classification Threshold...\n",
      "\n",
      "üìä Threshold Analysis:\n",
      "  Recall=70%: threshold=0.193, precision=17.3%\n",
      "  Best F1:    threshold=0.327, recall=47.3%, precision=25.6%\n",
      "  Prec>=30%:  threshold=0.412, recall=31.7%\n",
      "\n",
      "Recall_70 (threshold=0.193):\n",
      "  Recall: 70.0% | Precision: 17.3% | F1: 0.278\n",
      "  Confusion Matrix:\n",
      "[[15823  6580]\n",
      " [  591  1378]]\n",
      "\n",
      "Best_F1 (threshold=0.327):\n",
      "  Recall: 47.3% | Precision: 25.6% | F1: 0.333\n",
      "  Confusion Matrix:\n",
      "[[19703  2700]\n",
      " [ 1038   931]]\n",
      "\n",
      "Prec_30 (threshold=0.412):\n",
      "  Recall: 31.7% | Precision: 30.0% | F1: 0.308\n",
      "  Confusion Matrix:\n",
      "[[20945  1458]\n",
      " [ 1344   625]]\n",
      "\n",
      "Default_0.5 (threshold=0.500):\n",
      "  Recall: 20.2% | Precision: 36.2% | F1: 0.259\n",
      "  Confusion Matrix:\n",
      "[[21701   702]\n",
      " [ 1571   398]]\n",
      "\n",
      "üéØ Threshold-Independent Metrics:\n",
      "  AUC-ROC: 0.7731\n",
      "  AUC-PR:  0.2644\n",
      "\n",
      "‚úÖ Model and thresholds saved!\n",
      "  - artifacts/xgboost_smote.pkl\n",
      "  - artifacts/optimal_thresholds.csv\n",
      "  - artifacts/threshold_comparison.csv\n",
      "\n",
      "================================================================================\n",
      "üí° RECOMMENDATIONS\n",
      "================================================================================\n",
      "\n",
      "üéØ For Maximum Recall (catch more defaulters):\n",
      "   Use threshold: 0.193\n",
      "   Recall: 70.0%\n",
      "   Precision: 17.3%\n",
      "\n",
      "‚öñÔ∏è For Balanced Performance (F1):\n",
      "   Use threshold: 0.327\n",
      "   Recall: 47.3%\n",
      "   Precision: 25.6%\n",
      "\n",
      "üìä Results Summary:\n",
      "Threshold_Strategy  Threshold   Recall  Precision       F1\n",
      "         Recall_70   0.192501 0.699848   0.173159 0.277627\n",
      "           Best_F1   0.327399 0.472829   0.256403 0.332500\n",
      "           Prec_30   0.412306 0.317420   0.300048 0.308490\n",
      "       Default_0.5   0.500000 0.202133   0.361818 0.259368\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, \n",
    "    classification_report, confusion_matrix,\n",
    "    precision_recall_curve\n",
    ")\n",
    "import time\n",
    "\n",
    "# =====================================================================\n",
    "# STEP 1: LOAD DATA\n",
    "# =====================================================================\n",
    "print(\"=\"*80)\n",
    "print(\"üè¶ LOAN DEFAULT PREDICTION - IMPROVED SMOTE PIPELINE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "X_train = pd.read_csv('processed_data/X_train_encoded.csv')\n",
    "X_test = pd.read_csv('processed_data/X_test_encoded.csv')\n",
    "y_train = pd.read_csv('processed_data/y_train.csv').values.ravel()\n",
    "y_test = pd.read_csv('processed_data/y_test.csv').values.ravel()\n",
    "\n",
    "print(f\"Training data: {X_train.shape}, Imbalance: {(y_train==0).sum()/(y_train==1).sum():.1f}:1\")\n",
    "\n",
    "# =====================================================================\n",
    "# STEP 2: APPLY SMOTE WITH CONSERVATIVE RATIO\n",
    "# =====================================================================\n",
    "print(\"\\n‚öñÔ∏è Applying SMOTE with conservative ratio...\")\n",
    "\n",
    "# Option A: Use moderate sampling (recommended)\n",
    "smote = SMOTE(\n",
    "    sampling_strategy=0.3,  # Bring minority to 30% of majority (not 100%)\n",
    "    random_state=42,\n",
    "    k_neighbors=5\n",
    ")\n",
    "\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"‚úì Balanced data shape: {X_train_balanced.shape}\")\n",
    "print(f\"‚úì New ratio: {(y_train_balanced==0).sum()/(y_train_balanced==1).sum():.2f}:1\")\n",
    "print(f\"‚úì Class distribution: {np.bincount(y_train_balanced)}\")\n",
    "\n",
    "# =====================================================================\n",
    "# STEP 3: TRAIN XGBOOST WITH ADJUSTED PARAMS\n",
    "# =====================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üöÄ Training XGBoost (SMOTE + Tuned)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Adjust scale_pos_weight based on new ratio\n",
    "new_ratio = (y_train_balanced==0).sum() / (y_train_balanced==1).sum()\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    # Use your best params from original tuning\n",
    "    n_estimators=500,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.03,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    min_child_weight=5,\n",
    "    gamma=0,\n",
    "    scale_pos_weight=new_ratio,  # Adjust to new ratio\n",
    "    random_state=42,\n",
    "    eval_metric='aucpr',  # Focus on AUC-PR\n",
    "    early_stopping_rounds=50,\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "xgb_model.fit(\n",
    "    X_train_balanced, \n",
    "    y_train_balanced,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    verbose=False\n",
    ")\n",
    "train_time = time.time() - start\n",
    "\n",
    "# Get probability predictions\n",
    "y_pred_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# =====================================================================\n",
    "# STEP 4: FIND OPTIMAL THRESHOLD\n",
    "# =====================================================================\n",
    "print(\"\\nüéØ Finding Optimal Classification Threshold...\")\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
    "\n",
    "# Strategy 1: Target Recall = 70%\n",
    "target_recall = 0.70\n",
    "idx_recall = np.argmin(np.abs(recalls - target_recall))\n",
    "threshold_recall_70 = thresholds[idx_recall]\n",
    "\n",
    "# Strategy 2: Maximize F1-Score\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)\n",
    "idx_f1 = np.argmax(f1_scores)\n",
    "threshold_f1 = thresholds[idx_f1]\n",
    "\n",
    "# Strategy 3: Target Precision >= 30%\n",
    "valid_idx = np.where(precisions >= 0.30)[0]\n",
    "if len(valid_idx) > 0:\n",
    "    idx_prec = valid_idx[np.argmax(recalls[valid_idx])]\n",
    "    threshold_prec_30 = thresholds[idx_prec]\n",
    "else:\n",
    "    threshold_prec_30 = 0.5\n",
    "\n",
    "print(f\"\\nüìä Threshold Analysis:\")\n",
    "print(f\"  Recall=70%: threshold={threshold_recall_70:.3f}, precision={precisions[idx_recall]:.1%}\")\n",
    "print(f\"  Best F1:    threshold={threshold_f1:.3f}, recall={recalls[idx_f1]:.1%}, precision={precisions[idx_f1]:.1%}\")\n",
    "print(f\"  Prec>=30%:  threshold={threshold_prec_30:.3f}, recall={recalls[idx_prec]:.1%}\")\n",
    "\n",
    "# =====================================================================\n",
    "# STEP 5: EVALUATE WITH MULTIPLE THRESHOLDS\n",
    "# =====================================================================\n",
    "thresholds_to_test = {\n",
    "    'Recall_70': threshold_recall_70,\n",
    "    'Best_F1': threshold_f1,\n",
    "    'Prec_30': threshold_prec_30,\n",
    "    'Default_0.5': 0.5\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, threshold in thresholds_to_test.items():\n",
    "    y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "    \n",
    "    from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "    \n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'Threshold_Strategy': name,\n",
    "        'Threshold': threshold,\n",
    "        'Recall': recall,\n",
    "        'Precision': precision,\n",
    "        'F1': f1\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{name} (threshold={threshold:.3f}):\")\n",
    "    print(f\"  Recall: {recall:.1%} | Precision: {precision:.1%} | F1: {f1:.3f}\")\n",
    "    print(f\"  Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Overall metrics (threshold-independent)\n",
    "auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "auc_pr = average_precision_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"\\nüéØ Threshold-Independent Metrics:\")\n",
    "print(f\"  AUC-ROC: {auc_roc:.4f}\")\n",
    "print(f\"  AUC-PR:  {auc_pr:.4f}\")\n",
    "\n",
    "# =====================================================================\n",
    "# STEP 6: SAVE BEST MODEL WITH RECOMMENDED THRESHOLD\n",
    "# =====================================================================\n",
    "import joblib\n",
    "\n",
    "# Save model\n",
    "joblib.dump(xgb_model, 'artifacts/xgboost_smote.pkl')\n",
    "\n",
    "# Save optimal thresholds\n",
    "threshold_info = pd.DataFrame([{\n",
    "    'strategy': name,\n",
    "    'threshold': threshold,\n",
    "    'description': f'Optimized for {name}'\n",
    "} for name, threshold in thresholds_to_test.items()])\n",
    "\n",
    "threshold_info.to_csv('artifacts/optimal_thresholds.csv', index=False)\n",
    "\n",
    "# Save results\n",
    "results_df = pd.DataFrame(results)\n",
    "# results_df.to_csv('artifacts/threshold_comparison.csv', index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Model and thresholds saved!\")\n",
    "print(f\"  - artifacts/xgboost_smote.pkl\")\n",
    "print(f\"  - artifacts/optimal_thresholds.csv\")\n",
    "print(f\"  - artifacts/threshold_comparison.csv\")\n",
    "\n",
    "# =====================================================================\n",
    "# STEP 7: FINAL RECOMMENDATION\n",
    "# =====================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üí° RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find best threshold based on business objective\n",
    "best_recall_idx = results_df['Recall'].idxmax()\n",
    "best_f1_idx = results_df['F1'].idxmax()\n",
    "\n",
    "print(f\"\\nüéØ For Maximum Recall (catch more defaulters):\")\n",
    "print(f\"   Use threshold: {results_df.loc[best_recall_idx, 'Threshold']:.3f}\")\n",
    "print(f\"   Recall: {results_df.loc[best_recall_idx, 'Recall']:.1%}\")\n",
    "print(f\"   Precision: {results_df.loc[best_recall_idx, 'Precision']:.1%}\")\n",
    "\n",
    "print(f\"\\n‚öñÔ∏è For Balanced Performance (F1):\")\n",
    "print(f\"   Use threshold: {results_df.loc[best_f1_idx, 'Threshold']:.3f}\")\n",
    "print(f\"   Recall: {results_df.loc[best_f1_idx, 'Recall']:.1%}\")\n",
    "print(f\"   Precision: {results_df.loc[best_f1_idx, 'Precision']:.1%}\")\n",
    "\n",
    "print(\"\\nüìä Results Summary:\")\n",
    "print(results_df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PublicSapient (3.10.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
